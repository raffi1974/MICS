{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pyreadstat\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bh.sav', 'ch.sav', 'fs.sav', 'hh.sav', 'hl.sav', 'wm.sav']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "os.chdir('C:/Users/511232/Desktop/MICS/microdata')\n",
    "[f for f in os.listdir() if 'sav' in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('C:/Users/511232/Desktop/MICS/microdata')\n",
    "df_hh,meta_hh=pyreadstat.read_sav('hh.sav', apply_value_formats=False)\n",
    "df_wm,meta_wm=pyreadstat.read_sav('wm.sav', apply_value_formats=False)\n",
    "df_hl,meta_hl=pyreadstat.read_sav('hl.sav', apply_value_formats=False)\n",
    "\n",
    "col_names_hh=meta_hh.column_names_to_labels\n",
    "col_vals_hh=meta_hh.variable_value_labels\n",
    "col_names_hl=meta_hl.column_names_to_labels\n",
    "col_vals_hl=meta_hl.variable_value_labels\n",
    "col_names_wm=meta_wm.column_names_to_labels\n",
    "col_vals_wm=meta_wm.variable_value_labels\n",
    "\n",
    "data_hh=df_hh.copy()\n",
    "data_wm=df_wm.copy()\n",
    "data_hl=df_hl.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0    9572\n",
       "1.0     222\n",
       "Name: disability, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_wm['disability'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''data processing prior to generating crosstabs'''\n",
    "\n",
    "class transform:\n",
    "\n",
    "    def __init__(self):\n",
    "        #reading in the .sav files and their metadata files\n",
    "        os.chdir('C:/Users/511232/Desktop/MICS/microdata')\n",
    "        df_hh,meta_hh=pyreadstat.read_sav('hh.sav', apply_value_formats=False)\n",
    "        df_wm,meta_wm=pyreadstat.read_sav('wm.sav', apply_value_formats=False)\n",
    "        df_hl,meta_hl=pyreadstat.read_sav('hl.sav', apply_value_formats=False)\n",
    "        \n",
    "        self.col_names_hh=meta_hh.column_names_to_labels\n",
    "        self.col_vals_hh=meta_hh.variable_value_labels\n",
    "        self.col_names_hl=meta_hl.column_names_to_labels\n",
    "        self.col_vals_hl=meta_hl.variable_value_labels\n",
    "        self.col_names_wm=meta_wm.column_names_to_labels\n",
    "        self.col_vals_wm=meta_wm.variable_value_labels\n",
    "\n",
    "        self.data_hh=df_hh.copy()\n",
    "        self.data_wm=df_wm.copy()\n",
    "        self.data_hl=df_hl.copy()\n",
    "\n",
    "        self.disability_levels={1:'No difficulty',\n",
    "        2:'Some difficulty',\n",
    "        3:'A lot of difficulty',\n",
    "        4:'Cannot do at all'}\n",
    "        \n",
    "        self.disability_cols=['AF6','AF8','AF9','AF10','AF11','AF12']\n",
    "        self.other_cols=['WAGE','HH6','disability','windex5u','windex5r','windex5','MSTATUS','HC14']\n",
    "\n",
    "        self.dis_names={'AF6': 'Difficulty seeing, even if wearing glasses or contact lenses',\n",
    "        'AF8': 'Difficulty hearing, even if using a hearing aid',\n",
    "        'AF9': 'Difficulty walking or climbing steps',\n",
    "        'AF10': 'Difficulty remembering or concentrating',\n",
    "        'AF11': 'Difficulty with self-care, such as washing all over or dressing',\n",
    "        'AF12': 'Difficulty communicating'}\n",
    "\n",
    "    def process_data(self):\n",
    "\n",
    "        os.chdir('C:/Users/511232/Desktop/MICS/Crosstabs')\n",
    "        ###################### VARIABLE CREATION & MERGES #####################################\n",
    "        ################create hh_type####################################\n",
    "        #calculate hh_type variable from HL3 from dataframe df_hl\n",
    "        def family_type(df):\n",
    "            nuclear=[1,2,3,13]\n",
    "            extended=nuclear+[4,5,6,7,8,9,10,11,12]\n",
    "            composite=extended+[14,96,98]\n",
    "\n",
    "            if all(df['HL3'].isin(nuclear)):\n",
    "                df['hh_type']='Nuclear'\n",
    "            elif all(df['HL3'].isin(extended)):\n",
    "                df['hh_type']='Extended'\n",
    "            elif all(df['HL3'].isin(composite)):\n",
    "                df['hh_type']='Composite'\n",
    "            else:\n",
    "                df['hh_type']='Unknown'\n",
    "            return(df)\n",
    "        \n",
    "        #create hh_type\n",
    "        self.data_hl=self.data_hl.groupby(['HH1','HH2']).apply(family_type)\n",
    "\n",
    "        #MERGE data_hh to data_wm on [HH1,HH2] to add HC14\n",
    "        right_df=self.data_hh[['HH1','HH2','HC14']]\n",
    "        left_df=self.data_wm\n",
    "        self.data_wm=pd.merge(left_df,right_df, how='left',on=['HH1','HH2'])\n",
    "\n",
    "        #create hh_size\n",
    "        self.data_hh['hh_size']=np.where(process.data_hh['HH48']>=8, '8+',process.data_hh['HH48'])\n",
    "        #create living_alone\n",
    "        cond=[self.data_hh['HH48']==1,self.data_hh['HH48'].isna(), self.data_hh['HH48']>1]\n",
    "        result=['alone','Missing','not alone']\n",
    "        self.data_hh['living_alone']=np.select(cond,result)\n",
    "        #MERGE data_hh with data_hl to get 'hh_size','living_alone'\n",
    "        right_df=self.data_hh[['HH1','HH2','hh_size','living_alone']]\n",
    "        left_df=self.data_hl\n",
    "        self.df_hl=pd.merge(left_df,right_df, how='left',on=['HH1','HH2'])\n",
    "        \n",
    "        #MERGE data_hl with data_wm to add 'hh_size','HL3'(household head relation),'HL6'(age),'hh_type'\n",
    "        right_df=self.df_hl[['HH1','HH2','HL1','hh_size','HL3','HL6','hh_type','living_alone']]\n",
    "        left_df=self.data_wm\n",
    "        self.data_wm=pd.merge(left_df,right_df, how='left', \n",
    "        left_on=['HH1','HH2','LN'], right_on=['HH1','HH2','HL1'])\n",
    "\n",
    "        #create 'disability_combined' variable. takes the max(code) among ['AF6','AF8','AF9','AF10','AF11','AF12']\n",
    "        self.data_wm['disability_combined']=self.data_wm[self.disability_cols].apply(lambda x: x.max(), axis=1)\n",
    "        self.data_wm['disability_combined']=self.data_wm['disability_combined'].map(self.disability_levels)\n",
    "        #create head of household relationship variable as 1:HH 2:Other \n",
    "        self.data_wm['hh_rel']=np.where(self.data_wm['HL3']==1,1,2)\n",
    "        self.data_wm['hh_rel']=self.data_wm['hh_rel'].map({1:'Head of household', 2:'Other'})\n",
    "\n",
    "        ###################### LABEL VALUES #########################################\n",
    "        for col in self.other_cols:\n",
    "            if col in self.col_vals_hh.keys():\n",
    "                self.data_wm[col]=self.data_wm[col].map(self.col_vals_hh[col])\n",
    "                print(f'{col} codes are translated from meta hh')\n",
    "            elif col in self.col_vals_wm.keys():\n",
    "                self.data_wm[col]=self.data_wm[col].map(self.col_vals_wm[col])\n",
    "                print(f'{col} codes are translated from meta women')\n",
    "            elif col in self.col_vals_hl.keys():\n",
    "                self.data_wm[col]=self.data_wm[col].map(self.col_vals_hl[col])\n",
    "                print(f'{col} codes are translated from meta hhl')\n",
    "            else:\n",
    "                print(f'!!! WARNING !!! {col} codes were not translated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WAGE codes are translated from meta women\n",
      "HH6 codes are translated from meta hh\n",
      "disability codes are translated from meta women\n",
      "windex5u codes are translated from meta hh\n",
      "windex5r codes are translated from meta hh\n",
      "windex5 codes are translated from meta hh\n",
      "MSTATUS codes are translated from meta women\n",
      "HC14 codes are translated from meta hh\n"
     ]
    }
   ],
   "source": [
    "process=transform()\n",
    "process.process_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Table 1\n",
    "steps:\n",
    "'disability_combined' column is calculated by taking the max(code) among ['AF6','AF8','AF9','AF10','AF11','AF12']\n",
    "'''\n",
    "\n",
    "def combined_disabilities(age_disaggregated=1):\n",
    "    \n",
    "    df=process.data_wm.copy()\n",
    "    #crosstab\n",
    "    if age_disaggregated:\n",
    "        xtab=pd.crosstab([df['HH6'],df['disability'],df['disability_combined']],df['WAGE'],\n",
    "        rownames=['Area','Disability','Disability level'],colnames=['Age'], values=df['wmweight'], aggfunc='sum',dropna=False)      \n",
    "        #export as excel\n",
    "        xtab.to_excel('xtab_all_dis_ByAge.xlsx')\n",
    "    else:\n",
    "        xtab=pd.crosstab([df['disability'],df['disability_combined']],df['HH6'],\n",
    "        rownames=['Disability','Disability level'],colnames=['Area'], values=df['wmweight'], aggfunc='sum',dropna=False)\n",
    "        #export as excel\n",
    "        xtab.to_excel('xtab_all_dis_ByTotalAge.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_disabilities(age_disaggregated=1)\n",
    "combined_disabilities(age_disaggregated=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Table 2\n",
    "steps:\n",
    "-generate separate xtabs for all disability_cols\n",
    "-stack() them to have a multiindex series and add them to a generator\n",
    "-concatenate the generator items\n",
    "-stack() and unstack() to get to the final result \n",
    "'''\n",
    "\n",
    "def separate_disabilities():\n",
    "        \n",
    "    #will generate a list of multiindex series for each disability\n",
    "    #generate a crosstab then stack to make it a multiindex series and put them \n",
    "    #all in a generator\n",
    "    df=process.data_wm.copy()\n",
    "    def xtab():\n",
    "        for col in process.disability_cols:\n",
    "            print(f'processing column {col}')\n",
    "            #translate the codes\n",
    "            df[col]=df[col].map(process.disability_levels)\n",
    "            r=pd.crosstab([df['HH6'],df['disability'],df[col]],df['WAGE'],\\\n",
    "                rownames=['Area','Disability','Level'],colnames=['Age'], values=df['wmweight'], aggfunc='sum').stack()\n",
    "            r.name=process.dis_names[col]\n",
    "            yield(r)\n",
    "\n",
    "    #concatenating the series in the resulting generator\n",
    "    s=xtab()\n",
    "    t=pd.concat(s, axis=1)\n",
    "    t['All_disabilities']=t.sum(axis=1)\n",
    "\n",
    "    #reshape the result\n",
    "    T=t.stack().unstack([4,3]).sort_index(axis=1, level=0)\n",
    "    T.to_excel('separate disabilites.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing column AF6\n",
      "processing column AF8\n",
      "processing column AF9\n",
      "processing column AF10\n",
      "processing column AF11\n",
      "processing column AF12\n"
     ]
    }
   ],
   "source": [
    "separate_disabilities()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Table 4\n",
    "steps:\n",
    "-calculate domain_num by summing the True over the array of disability_cols values\n",
    "if the array contains codes (3-a lot of difficulty) or (4-cannot at all) it will reult as True\n",
    "'''\n",
    "def num_dis_domain():\n",
    "    \n",
    "    #for each row under disability_cols if the row contains 3 or 4 then True\n",
    "    #sum over all the True/False results \n",
    "    df=process.data_wm.copy()\n",
    "    df['domain_num']=df[process.disability_cols].apply(lambda x: sum(x.isin([3,4])), axis=1)\n",
    "    #generate xtab\n",
    "    r=pd.crosstab([df['HH6'],df['disability']],df['domain_num'],\\\n",
    "        rownames=['Area','Disability'],colnames=['Number of domains'], values=df['wmweight'], aggfunc='sum', dropna=False)\n",
    "    \n",
    "    r.to_excel('Number_dis_domain.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_dis_domain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Table 5 marital status'''\n",
    "\n",
    "def marital_status():\n",
    "    \n",
    "    df=process.data_wm.copy()\n",
    "    #crosstab\n",
    "    xtab=pd.crosstab([df['HH6'],df['MSTATUS'],df['disability'],df['disability_combined']],df['WAGE'],\n",
    "    rownames=['Area','Marital status','Disability','Disability level'],colnames=['Age'], values=df['wmweight'],\n",
    "    aggfunc='sum',dropna=False)      \n",
    "    #export as excel\n",
    "    xtab.to_excel('MaritalStatus.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "marital_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Table 6: head_HH 2 crosstabs \n",
    "1-disability against head of household and othery type of relationship\n",
    "steps:\n",
    "-create head of household relationship (in the process_data_wm() )\n",
    "df['hh_rel']=np.where(df['HL3']==1,1,2) where 1:HH 2:Other \n",
    "2-disability by head of households by wealth quintiles\n",
    "steps\n",
    "-will generate crosstab among disabled HH with wealth quintiles \n",
    "using windex and not specific windex5u for urban and windex5r for rural since\n",
    "they differ from windex5 and will produce contradictory results between urban and rural xtabs\n",
    "and the urban and rural disaggregation in the xtab for the total: camp/urban/rural\n",
    "'''\n",
    "def head_HH(quintile=0):\n",
    "    \n",
    "    df=process.data_wm.copy()\n",
    "    if not quintile:\n",
    "        #crosstab\n",
    "        xtab=pd.crosstab([df['HH6'],df['disability'],df['disability_combined']],df['hh_rel'],\n",
    "        rownames=['Area','Disability','Disability level'],colnames=['HH relationship'], values=df['wmweight'],\n",
    "        aggfunc='sum',dropna=False)\n",
    "\n",
    "        #export as excel\n",
    "        xtab.to_excel('head of HH.xlsx')\n",
    "    else:\n",
    "        #filter out the HH\n",
    "        df_hh_only=df[df['hh_rel']=='Head of household']\n",
    "        #crosstab\n",
    "        xtab=pd.crosstab([df_hh_only['HH6'],df_hh_only['disability'],df_hh_only['disability_combined']],df_hh_only['windex5'],\n",
    "        rownames=['Area','Disability','Disability level'],colnames=['wealth quintile'], values=df_hh_only['wmweight'],\n",
    "        aggfunc='sum',dropna=False)\n",
    "        xtab.to_excel('head of HH_with wquintile.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "head_HH(quintile=0)\n",
    "head_HH(quintile=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Table 7: Poorest_type\n",
    "steps\n",
    "-filter out the poorest quintile 'windex5' and crosstab with all disability types\n",
    "-loop over disability_cols and create crosstabs then stack to end up with multiindex series\n",
    "-put them in a generator and concatenate the generator items\n",
    "'''\n",
    "\n",
    "def poorest_type():\n",
    "    \n",
    "    df=process.data_wm.copy()\n",
    "    #filter out the poorest\n",
    "    df_poorest=df[df['windex5']=='Poorest'].copy()\n",
    "\n",
    "    #will generate a list of multiindex series for each disability\n",
    "    #generate a crosstab then stack to make it a multiindex series and put them \n",
    "    #all in a generator\n",
    "    def xtab():\n",
    "        for col in process.disability_cols:\n",
    "            print(f'processing column {col}')\n",
    "            #translate the codes\n",
    "            df_poorest[col]=df_poorest[col].map(process.disability_levels)\n",
    "            r=pd.crosstab([df_poorest['HH6'],df_poorest['disability']],df_poorest[col],\\\n",
    "                rownames=['Area','Disability'],colnames=['Disability level'], values=df_poorest['wmweight'], aggfunc='sum').stack()\n",
    "            r.name=process.dis_names[col]\n",
    "            yield(r)\n",
    "\n",
    "    #concatenating the series in the resulting generator\n",
    "    s=xtab()\n",
    "    t=pd.concat(s, axis=1)\n",
    "    t['All_disabilities']=t.sum(axis=1)\n",
    "    t.to_excel('poorest_type.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing column AF6\n",
      "processing column AF8\n",
      "processing column AF9\n",
      "processing column AF10\n",
      "processing column AF11\n",
      "processing column AF12\n"
     ]
    }
   ],
   "source": [
    "poorest_type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Table 8: HH_type&size\n",
    "Households with one or more persons with disabilities (18 years and older), by location and type and size of household\n",
    "steps\n",
    "-data_wm will be filtered according to (age>=18 & disability_combined==3,4) \n",
    "-get the 'HH1','HH2' of the resulting dataframe as a list by zipping both columns\n",
    "-filter data resulting from  process_data_wm() on the tuple ('HH1','HH2')\n",
    "\n",
    "steps for calculating type of household hh_type (in hl dataframe):\n",
    "-grouby hl by ['HH1','HH2']\n",
    "-if HL3 isin (1 head,2 spouse/partner,3 son/daughter,13 adopted son daughter)\n",
    "if ALL TRUE then code hh_type as 1 Nuclear\n",
    "-if HL3 isin (1 head,2 spouse/partner,3 son/daughter,13 adopted son daughter,\n",
    "4 son /daughter in law, 5 grnachild, 6 parent, 7 parentin law, 8 brother/sister,\n",
    "9, brother/sis in law, 10 uncle/aunt, 11 nephew/niece, 12 other)\n",
    "if ALL TRUE then code hh_type as 2 Extended\n",
    "if HL3 isin (1 head,2 spouse/partner,3 son/daughter,13 adopted son daughter,\n",
    "4 son /daughter in law, 5 grandchild, 6 parent, 7 parent in law, 8 brother/sister,\n",
    "9, brother/sis in law, 10 uncle/aunt, 11 nephew/niece, 12 other, 14 servant, 96 other, 98 dont know)\n",
    "if ALL TRUE then code hh_type as 3 composite\n",
    "WARNING: there is no way to distinguish two nuclear families in a single household from one\n",
    "since for example a HH might have 2 spouses or more \n",
    "-data_wm with merge hl left_on=['HH1','HH2','LN'], right_on=['HH1','HH2','HL1'])\n",
    "to get the hh_type variable\n",
    "-perform corsstab\n",
    "'''\n",
    "\n",
    "def HH_type_size():\n",
    "\n",
    "    df_w=process.data_wm.copy()\n",
    "    #criteria 1 for being disabled, and criteria 2 for being >=18\n",
    "    criteria1=((df_w['disability_combined']=='Cannot do at all')|(df_w['disability_combined']=='A lot of difficulty'))\n",
    "    criteria2=(df_w['HL6']>=18)\n",
    "\n",
    "    #filter according to criteria1 & criteria2\n",
    "    df_filtered=df_w.loc[criteria1 & criteria2, ['HH1','HH2']].drop_duplicates()\n",
    "    # filter df_w according to resulting ['HH1','HH2']\n",
    "    hhd_filter=pd.Series(zip(df_w['HH1'],df_w['HH2'])).isin(list(zip(df_filtered['HH1'],df_filtered['HH2'])))\n",
    "    #filter according to tuple ('HH1','HH2')\n",
    "    df_wm_filtered=df_w[hhd_filter]\n",
    "\n",
    "    ########################################################################\n",
    "    #generate the crosstab\n",
    "    xtab=pd.crosstab([df_wm_filtered['HH6'],df_wm_filtered['hh_type']],\n",
    "    [df_wm_filtered['disability'],df_wm_filtered['disability_combined']],\n",
    "    rownames=['Area','Household type'],colnames=['Disability','Disability level'], values=df_wm_filtered['wmweight'],\n",
    "    aggfunc='sum',dropna=False)\n",
    "\n",
    "    xtab.to_excel('hh_type_size1.xlsx')\n",
    "\n",
    "    xtab=pd.crosstab([df_wm_filtered['HH6'],df_wm_filtered['hh_type']],df_wm_filtered['hh_size'],\n",
    "    rownames=['Area','Household type'],colnames=['Household size'], values=df_wm_filtered['wmweight'],\n",
    "    aggfunc='sum',dropna=False)\n",
    "\n",
    "    xtab.to_excel('hh_type_size2.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "HH_type_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Table 9: living_type_age\n",
    "rows: location(HH6), living_alone, hhd_inst (living alone, living with a family in hhd, living in institution)\n",
    "note: Palestine doesnt have a question for place of hh whether institution or not so in this case\n",
    "the hh_size is being used as alone versus not alone), disability (filter on disabled), disability combined\n",
    "columns: separate disabilities (that is on ['AF6','AF8','AF9','AF10','AF11','AF12']), agegroups (WAGE)'''\n",
    "\n",
    "def living_type_age():\n",
    "    \n",
    "    df_w=process.data_wm.copy()\n",
    "    #criteria 1 for being disabled, and criteria 2 for being >=18\n",
    "    criteria=((df_w['disability_combined']=='Cannot do at all')|(df_w['disability_combined']=='A lot of difficulty'))\n",
    "\n",
    "    #filter according to criteria1 & criteria2\n",
    "    df_filtered=df_w[criteria].copy()\n",
    "\n",
    "    #since we have 2 levels of columns, use stack() twice\n",
    "    def xtab():\n",
    "        for col in process.disability_cols:\n",
    "            print(f'processing column {col}')\n",
    "            #translate the codes\n",
    "            df_filtered[col]=df_filtered[col].map(process.disability_levels)\n",
    "            #generate the crosstab\n",
    "            r=pd.crosstab([df_filtered['HH6'],df_filtered['living_alone'],df_filtered['disability'],df_filtered['disability_combined']],\n",
    "            [df_filtered['WAGE']],\n",
    "            rownames=['Area','Living alone','Disability','Disability level'],colnames=['Age group'], values=df_filtered['wmweight'],\n",
    "            aggfunc='sum',dropna=False).stack()\n",
    "            r.name=process.dis_names[col]\n",
    "            yield(r)\n",
    "\n",
    "    #concatenating the series in the resulting generator\n",
    "    s=xtab()\n",
    "    t=pd.concat(s, axis=1)\n",
    "\n",
    "    #reshape the result\n",
    "    T=t.unstack([4]).sort_index(axis=1, level=0)\n",
    "    T.to_excel('living_type_age.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing column AF6\n",
      "processing column AF8\n",
      "processing column AF9\n",
      "processing column AF10\n",
      "processing column AF11\n",
      "processing column AF12\n"
     ]
    }
   ],
   "source": [
    "living_type_age()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Table 10: house_ownership \n",
    "(House ownership of population (18 years and older) living alone, by sex, location and disability status)\n",
    "filter data_wm on 'living_alone' and HL6>=18\n",
    "Rows: location (HH6), disability (disability), disability combined\n",
    "columns: house ownership (HC14: {1.0: 'OWN', 2.0: 'RENT', 6.0: 'OTHER', 9.0: 'NO RESPONSE'})'''\n",
    "\n",
    "def house_ownership():\n",
    "    df_w=process.data_wm.copy()\n",
    "\n",
    "    criteria=((df_w['HL6']>=18)&(df_w['living_alone']=='alone'))\n",
    "    #filter according to criteria1 & criteria2\n",
    "    df_filtered=df_w[criteria].copy()\n",
    "\n",
    "    #crosstab\n",
    "    r=pd.crosstab([df_filtered['HH6'],df_filtered['disability'],df_filtered['disability_combined']],\n",
    "    [df_filtered['HC14']],\n",
    "    rownames=['Area','Disability','Disability level'],colnames=['house ownership'], values=df_filtered['wmweight'],\n",
    "    aggfunc='sum',dropna=False)\n",
    "    r['Total 18+']=r.sum(axis=1)\n",
    "\n",
    "    r.to_excel('house_ownership.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_ownership()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0b35042a3e9702dfa19af850771da1f579b71240f0eb9d6f872f3083a53479fb"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 ('mics': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
