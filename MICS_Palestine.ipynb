{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pyreadstat\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bh.sav', 'ch.sav', 'fs.sav', 'hh.sav', 'hl.sav', 'wm.sav']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "os.chdir('C:/Users/511232/Desktop/MICS/microdata')\n",
    "[f for f in os.listdir() if 'sav' in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''data processing prior to generating crosstabs'''\n",
    "\n",
    "class process:\n",
    "\n",
    "    def __init__(self):\n",
    "        #reading in the .sav files and their metadata files\n",
    "        os.chdir('C:/Users/511232/Desktop/MICS/microdata')\n",
    "        df_hh,meta_hh=pyreadstat.read_sav('hh.sav', apply_value_formats=False)\n",
    "        df_wm,meta_wm=pyreadstat.read_sav('wm.sav', apply_value_formats=False)\n",
    "        df_hl,meta_hl=pyreadstat.read_sav('hl.sav', apply_value_formats=False)\n",
    "        \n",
    "        self.col_names_hh=meta_hh.column_names_to_labels\n",
    "        self.col_vals_hh=meta_hh.variable_value_labels\n",
    "        self.col_names_hl=meta_hl.column_names_to_labels\n",
    "        self.col_vals_hl=meta_hl.variable_value_labels\n",
    "        self.col_names_wm=meta_wm.column_names_to_labels\n",
    "        self.col_vals_wm=meta_wm.variable_value_labels\n",
    "\n",
    "        self.data_hh=df_hh.copy()\n",
    "        self.data_wm=df_wm.copy()\n",
    "        self.data_hl=df_hl.copy()\n",
    "\n",
    "        self.disability_levels={1:'No difficulty',\n",
    "        2:'Some difficulty',\n",
    "        3:'A lot of difficulty',\n",
    "        4:'Cannot do at all',\n",
    "        9: 'No response'}\n",
    "        \n",
    "        self.disability_cols=['AF6','AF8','AF9','AF10','AF11','AF12']\n",
    "        self.other_cols=['WAGE','HH6','disability','windex5u','windex5r','windex5','MSTATUS','HC14','WB6A','WB5','WB14',\n",
    "        'MT10','TA3','CP2','CM17','MA6']\n",
    "\n",
    "        self.dis_names={'AF6': 'Difficulty seeing, even if wearing glasses or contact lenses',\n",
    "        'AF8': 'Difficulty hearing, even if using a hearing aid',\n",
    "        'AF9': 'Difficulty walking or climbing steps',\n",
    "        'AF10': 'Difficulty remembering or concentrating',\n",
    "        'AF11': 'Difficulty with self-care, such as washing all over or dressing',\n",
    "        'AF12': 'Difficulty communicating'}\n",
    "\n",
    "    def process_data(self):\n",
    "\n",
    "        os.chdir('C:/Users/511232/Desktop/MICS/Crosstabs')\n",
    "        ###################### VARIABLE CREATION & MERGES #####################################\n",
    "        #calculate hh_type variable from HL3 from dataframe df_hl\n",
    "        def family_type(df):\n",
    "            nuclear=[1,2,3,13]\n",
    "            extended=nuclear+[4,5,6,7,8,9,10,11,12]\n",
    "            composite=extended+[14,96,98]\n",
    "\n",
    "            if len(df['HL3'])==1:\n",
    "                df['hh_type']='One person'\n",
    "            elif all(df['HL3'].isin(nuclear)):\n",
    "                df['hh_type']='Nuclear'\n",
    "            elif all(df['HL3'].isin(extended)):\n",
    "                df['hh_type']='Extended'\n",
    "            elif all(df['HL3'].isin(composite)):\n",
    "                df['hh_type']='Composite'\n",
    "            else:\n",
    "                df['hh_type']='Unknown'\n",
    "            return(df)\n",
    "        \n",
    "        #create hh_type\n",
    "        self.data_hl=self.data_hl.groupby(['HH1','HH2']).apply(family_type)\n",
    "\n",
    "        #create disability_combined from multiple disability types columns\n",
    "        #replace code 9 with 0 and take the maximum code within each row\n",
    "        self.data_wm['disability_combined']=self.data_wm[self.disability_cols].apply(lambda x: x.max(), axis=1)\n",
    "        self.data_wm['disability_combined']=self.data_wm['disability_combined'].map(self.disability_levels)\n",
    "\n",
    "        #create Smoker\n",
    "        ''' * Tobacco use.\n",
    "            IF ((TA1 = 9 | TA3 = 9 | TA5 = 99) | (TA6 = 9 | TA7 = 9|TA9=99) | (TA10 = 9 | TA11 = 9 | TA13 = 99)) TobaccoUse = missing.\n",
    "            IF ((TA1 = 2 | TA2=0 | TA3 = 2 | TA5 = 0) & (TA6 = 2 | TA7 = 2 | TA9=0) & (TA10 = 2|TA11 = 2 | TA13 = 0)) TobaccoUse = non-smoker.\n",
    "            IF ((TA5 > 0 & TA5 <99) | (TA9 > 0 & TA9 <99) | (TA13 > 0 & TA13 <99)) TobaccoUse = smoker.'''\n",
    "\n",
    "        cond_smoker_missing=((self.data_wm['TA1']==9) | (self.data_wm['TA3']==9) | (self.data_wm['TA5']==99)) | \\\n",
    "            ((self.data_wm['TA6']==9) | (self.data_wm['TA7']==9) | (self.data_wm['TA9']==99)) | \\\n",
    "                ((self.data_wm['TA10']==9) | (self.data_wm['TA11']==9) | (self.data_wm['TA13']==99))\n",
    "\n",
    "        cond_smoker=(((self.data_wm['TA5']>0) & (self.data_wm['TA5']<99)) | \\\n",
    "            ((self.data_wm['TA9']>0) & (self.data_wm['TA9']<99)) | \\\n",
    "                ((self.data_wm['TA13']>0) & (self.data_wm['TA13']<99)))\n",
    "        \n",
    "        cond_non_smoker=(((self.data_wm['TA1']==2) | (self.data_wm['TA2']==0) | (self.data_wm['TA3']==2) | (self.data_wm['TA5']==0)) & \\\n",
    "            ((self.data_wm['TA6']==2) | (self.data_wm['TA7']==2) | (self.data_wm['TA9']==0)) & \\\n",
    "                ((self.data_wm['TA10']==2) | (self.data_wm['TA11']==2) | (self.data_wm['TA13']==0)))\n",
    "\n",
    "        self.data_wm['Smoker']=np.select([cond_smoker_missing,cond_smoker,cond_non_smoker], \n",
    "        ['Missing','Smoker','Non-smoker'], default=np.nan)\n",
    "\n",
    "        #create literacy\n",
    "        '''literate (So if WB6A = 2 | WB6A = 3 | (WB6A = 1 & WB6B >=5) --> Literate)'''\n",
    "        cond=[(self.data_wm['WB14']==3) | (self.data_wm['WB6A']==2) | (self.data_wm['WB6A']==3) | ((self.data_wm['WB6A']==1) & (self.data_wm['WB6B']>=5)),\n",
    "        self.data_wm['WB14'].isna(),self.data_wm['WB14']==9]\n",
    "        rslt=['Literate',np.nan,'No response']\n",
    "        self.data_wm['Literacy']=np.select(cond,rslt,default='Illiterate')\n",
    "\n",
    "        #create edu_level  (!!!!WARNING!!! it only applies for PAlESTINE)\n",
    "        edu_lev_label={1:'ISCED X',2:'ISCED 0',3:'ISCED 1',4:'ISCED 2',5:'ISCED 3',6:'ISCED 4',7:'ISCED 5',\n",
    "        8:'ISCED 6',9:'ISCED 7',10:'ISCED 8',11:'Not classifiable', 12:'Not stated'}\n",
    "\n",
    "        cond=[self.data_wm['WB5']==2,self.data_wm['WB5']==9,\n",
    "        self.data_wm['WB6A']==0,self.data_wm['WB6A']==1,\n",
    "        self.data_wm['WB6A']==2,self.data_wm['WB6A']==3]\n",
    "\n",
    "        rslt=[1,12,2,3,5,8]\n",
    "\n",
    "        self.data_wm['edu_level']=np.select(cond,rslt)\n",
    "        self.data_wm['edu_level']=self.data_wm['edu_level'].map(edu_lev_label)\n",
    "\n",
    "        #create Birth_Skilled_Per 'Birth attended by skilled personnels'\n",
    "        '''IF (MN19A = \"?\" | MN19B = \"?\" | MN19H = \"?\" | MN19X = \"?\" | MN19Y = \"?\" | MN19NR = \"?\") Birth_Skilled_Per = 9.\n",
    "        IF (MN19H = \"H\" | MN19X = \"X\" | MN19Y = \"Y\") Birth_Skilled_Per = 2.\n",
    "        IF (MN19A = \"A\" | MN19B = \"B\") Birth_Skilled_Per = 1.\n",
    "        '''\n",
    "        Birth_Skilled_Per_label={1:'Yes', 2:'No', 9:'No repsonse'}\n",
    "        cond=[(self.data_wm['MN19A']=='A') | (self.data_wm['MN19B']=='B'),\n",
    "        (self.data_wm['MN19H']=='H') | (self.data_wm['MN19X']=='X') | (self.data_wm['MN19Y']=='Y'),\n",
    "        (self.data_wm['MN19NR']=='?')]\n",
    "        rslt=[1, 2,9]\n",
    "\n",
    "        self.data_wm['Birth_Skilled_Per']=np.select(cond,rslt,default=np.nan)\n",
    "        self.data_wm['Birth_Skilled_Per']=self.data_wm['Birth_Skilled_Per'].map(Birth_Skilled_Per_label)\n",
    "\n",
    "        #create age_groups columns\n",
    "        #agegrp4_1[5-9,10-14,15-19,20-24,25-29,30+]\n",
    "        cond=[(self.data_hl['HL6']>=5)&(self.data_hl['HL6']<=9),\n",
    "        (self.data_hl['HL6']>=10)&(self.data_hl['HL6']<=14),\n",
    "        (self.data_hl['HL6']>=15)&(self.data_hl['HL6']<=19),\n",
    "        (self.data_hl['HL6']>=20)&(self.data_hl['HL6']<=24),\n",
    "        (self.data_hl['HL6']>=25)&(self.data_hl['HL6']<=29),\n",
    "        self.data_hl['HL6']>=30,self.data_hl['HL6'].isna()]\n",
    "        result=['5-9','10-14','15-19','20-24','25-29','30+','Missing']\n",
    "        self.data_hl['agegrp4_1']=np.select(cond,result,default='<5')\n",
    "\n",
    "        #agegrp4_2 [5-9,10-14,15-19,20-24,25-64]\n",
    "        cond=[(self.data_hl['HL6']>=5)&(self.data_hl['HL6']<=9),\n",
    "        (self.data_hl['HL6']>=10)&(self.data_hl['HL6']<=14),\n",
    "        (self.data_hl['HL6']>=15)&(self.data_hl['HL6']<=19),\n",
    "        (self.data_hl['HL6']>=20)&(self.data_hl['HL6']<=24),\n",
    "        (self.data_hl['HL6']>=25)&(self.data_hl['HL6']<=64),\n",
    "        self.data_hl['HL6']>=65,self.data_hl['HL6'].isna()]\n",
    "        result=['5-9','10-14','15-19','20-24','25-64','65+','Missing']\n",
    "        self.data_hl['agegrp4_2']=np.select(cond,result,default='<5')\n",
    "\n",
    "        #age_ict [0-14,15-60,60+]\n",
    "        cond=[(self.data_hl['HL6']>=0)&(self.data_hl['HL6']<=14),\n",
    "        (self.data_hl['HL6']>=15)&(self.data_hl['HL6']<=60),\n",
    "        self.data_hl['HL6']>60,self.data_hl['HL6'].isna()]\n",
    "        result=['0-14','15-60','60+','Missing']\n",
    "        self.data_hl['age_ict']=np.select(cond,result,default='<5')\n",
    "\n",
    "        #agegrp5[<15,15-19,20-24,25-29,30-34,35-39,40-44,45-49,50-54,55-59,60-64,65+]\n",
    "        cond=[(self.data_hl['HL6']>=15)&(self.data_hl['HL6']<=19),\n",
    "        (self.data_hl['HL6']>=20)&(self.data_hl['HL6']<=24),\n",
    "        (self.data_hl['HL6']>=25)&(self.data_hl['HL6']<=29),\n",
    "        (self.data_hl['HL6']>=30)&(self.data_hl['HL6']<=34),\n",
    "        (self.data_hl['HL6']>=35)&(self.data_hl['HL6']<=39),\n",
    "        (self.data_hl['HL6']>=40)&(self.data_hl['HL6']<=44),\n",
    "        (self.data_hl['HL6']>=45)&(self.data_hl['HL6']<=49),\n",
    "        (self.data_hl['HL6']>=50)&(self.data_hl['HL6']<=54),\n",
    "        (self.data_hl['HL6']>=55)&(self.data_hl['HL6']<=59),\n",
    "        (self.data_hl['HL6']>=60)&(self.data_hl['HL6']<=64),\n",
    "        self.data_hl['HL6']>=65,self.data_hl['HL6'].isna()]\n",
    "        result=['15-19','20-24','25-29','30-34','35-39','40-44','45-49','50-54','55-59','60-64','65+','Missing']\n",
    "        self.data_hl['agegrp5']=np.select(cond,result,default='<15')\n",
    "\n",
    "        #agegrp15[15-29,30-44,45-64,65+]\n",
    "        cond=[(self.data_hl['HL6']>=15)&(self.data_hl['HL6']<=29),\n",
    "        (self.data_hl['HL6']>=30)&(self.data_hl['HL6']<=44),\n",
    "        (self.data_hl['HL6']>=45)&(self.data_hl['HL6']<=64),\n",
    "        self.data_hl['HL6']>=65,self.data_hl['HL6'].isna()]\n",
    "        result=['15-29','30-44','45-64','65+','Missing']\n",
    "        self.data_hl['agegrp15']=np.select(cond,result,default='<15')\n",
    "\n",
    "        #agegrp10 [15-24, 25-64, 65+]\n",
    "        cond=[(self.data_hl['HL6']>=15)&(self.data_hl['HL6']<=24),\n",
    "        (self.data_hl['HL6']>=25)&(self.data_hl['HL6']<=64),\n",
    "        self.data_hl['HL6']>=65,self.data_hl['HL6'].isna()]\n",
    "        result=['15-24','25-64','65+','Missing']\n",
    "        self.data_hl['agegrp10']=np.select(cond,result,default='<15')\n",
    "\n",
    "        #agegrp_9 [<18,18-24,25-64,65+,'Not stated']\n",
    "        cond=[(self.data_hl['HL6']<18),\n",
    "        (self.data_hl['HL6']>=18)&(self.data_hl['HL6']<=24),\n",
    "        (self.data_hl['HL6']>=25)&(self.data_hl['HL6']<=64),\n",
    "        self.data_hl['HL6']>=65,\n",
    "        self.data_hl['HL6'].isna()]\n",
    "        result=['<18','18-24','25-64','65+','Not stated']\n",
    "        self.data_hl['agegrp_9']=np.select(cond,result)\n",
    "\n",
    "        #agegrp5p age 5+\n",
    "        cond=[self.data_hl['HL6']>=5,self.data_hl['HL6'].isna()]\n",
    "        result=['5+','Missing']\n",
    "        self.data_hl['agegrp5p']=np.select(cond,result,default='<5')\n",
    "\n",
    "        #agegrp15p age 15+\n",
    "        cond=[self.data_hl['HL6']>=15,self.data_hl['HL6'].isna()]\n",
    "        result=['15+','Missing']\n",
    "        self.data_hl['agegrp15p']=np.select(cond,result,default='<15')\n",
    "\n",
    "        #agegrp18p age 18+\n",
    "        cond=[self.data_hl['HL6']>=18,self.data_hl['HL6'].isna()]\n",
    "        result=['18+','Missing']\n",
    "        self.data_hl['agegrp18p']=np.select(cond,result,default='<18')\n",
    "\n",
    "        #agegrp25p age 25+\n",
    "        cond=[self.data_hl['HL6']>=25,self.data_hl['HL6'].isna()]\n",
    "        result=['25+','Missing']\n",
    "        self.data_hl['agegrp25p']=np.select(cond,result,default='<25')\n",
    "\n",
    "        #create hh_size\n",
    "        self.data_hh['hh_size']=np.where(self.data_hh['HH48']>=8, '8+',self.data_hh['HH48'])\n",
    "        #create living_alone\n",
    "        cond=[self.data_hh['HH48']==1,self.data_hh['HH48'].isna(), self.data_hh['HH48']>1]\n",
    "        result=['alone','Missing','not alone']\n",
    "        self.data_hh['living_alone']=np.select(cond,result)\n",
    "\n",
    "        #create modern method of contraception 'modern_contraceptive'\n",
    "        '''\n",
    "        'CP4A': {'?': 'NO RESPONSE', 'A': 'FEMALE STERILIZATION'},\n",
    "        'CP4B': {'?': 'NO RESPONSE', 'B': 'MALE STERILIZATION'},\n",
    "        'CP4C': {'?': 'NO RESPONSE', 'C': 'IUD'},\n",
    "        'CP4D': {'?': 'NO RESPONSE', 'D': 'INJECTABLES'},\n",
    "        'CP4E': {'?': 'NO RESPONSE', 'E': 'IMPLANTS'},\n",
    "        'CP4F': {'?': 'NO RESPONSE', 'F': 'PILL'},\n",
    "        'CP4G': {'?': 'NO RESPONSE', 'G': 'MALE CONDOM'},\n",
    "        'CP4H': {'?': 'NO RESPONSE', 'H': 'FEMALE CONDOM'},\n",
    "        'CP4I': {'?': 'NO RESPONSE', 'I': 'DIAPHRAGM'},\n",
    "        'CP4J': {'?': 'NO RESPONSE', 'J': 'FOAM / JELLY'}'''\n",
    "\n",
    "        methods=['A','B','C','D','E','F','G','H','I','J']\n",
    "        cols=['CP4A','CP4B','CP4C','CP4D','CP4E','CP4F','CP4G','CP4H','CP4I','CP4J']\n",
    "        self.data_wm['modern_contraceptive']=self.data_wm[cols].apply(lambda x: int(any(x.isin(methods))), axis=1)\n",
    "        self.modern_contraceptive_labels={0:'No', 1:'Yes'}\n",
    "        self.data_wm['modern_contraceptive']=self.data_wm['modern_contraceptive'].map(self.modern_contraceptive_labels)\n",
    "\n",
    "        #MERGE [HH ---> WM] on [HH1,HH2] to add 'HC14': 'Household owns the dwelling'\n",
    "        right_df=self.data_hh[['HH1','HH2','HC14']]\n",
    "        left_df=self.data_wm\n",
    "        self.data_wm=pd.merge(left_df,right_df, how='left',on=['HH1','HH2'])\n",
    "        \n",
    "        #MERGE [HH ---> HL] to get 'hh_size','living_alone'\n",
    "        right_df=self.data_hh[['HH1','HH2','hh_size','living_alone']]\n",
    "        left_df=self.data_hl\n",
    "        self.df_hl=pd.merge(left_df,right_df, how='left',on=['HH1','HH2'])\n",
    "        \n",
    "        #MERGE [HL ---> WM] to add 'hh_size','HL3'(household head relation),'HL6'(age),'hh_type'\n",
    "        right_df=self.df_hl[['HH1','HH2','HL1','hh_size','HL3','HL6','hh_type',\n",
    "        'living_alone','agegrp4_1','agegrp4_2','agegrp10','agegrp15','agegrp5p','agegrp15p','agegrp25p','agegrp5',\n",
    "        'agegrp_9','age_ict','agegrp18p']]\n",
    "        left_df=self.data_wm\n",
    "        self.data_wm=pd.merge(left_df,right_df, how='left', \n",
    "        left_on=['HH1','HH2','LN'], right_on=['HH1','HH2','HL1'])\n",
    "\n",
    "        #create head of household relationship variable as 1:HH 2:Other \n",
    "        self.data_wm['hh_rel']=np.where(self.data_wm['HL3']==1,1,2)\n",
    "        self.data_wm['hh_rel']=self.data_wm['hh_rel'].map({1:'Head of household', 2:'Other'})\n",
    "\n",
    "        ###################### LABEL VALUES #########################################\n",
    "        for col in self.other_cols:\n",
    "            if col in self.col_vals_hh.keys():\n",
    "                self.data_wm[col]=self.data_wm[col].map(self.col_vals_hh[col])\n",
    "                print(f'{col} codes are translated from meta hh')\n",
    "            elif col in self.col_vals_wm.keys():\n",
    "                self.data_wm[col]=self.data_wm[col].map(self.col_vals_wm[col])\n",
    "                print(f'{col} codes are translated from meta women')\n",
    "            elif col in self.col_vals_hl.keys():\n",
    "                self.data_wm[col]=self.data_wm[col].map(self.col_vals_hl[col])\n",
    "                print(f'{col} codes are translated from meta hhl')\n",
    "            else:\n",
    "                print(f'!!! WARNING !!! {col} codes were not translated')\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WAGE codes are translated from meta women\n",
      "HH6 codes are translated from meta hh\n",
      "disability codes are translated from meta women\n",
      "windex5u codes are translated from meta hh\n",
      "windex5r codes are translated from meta hh\n",
      "windex5 codes are translated from meta hh\n",
      "MSTATUS codes are translated from meta women\n",
      "HC14 codes are translated from meta hh\n",
      "WB6A codes are translated from meta women\n",
      "WB5 codes are translated from meta women\n",
      "WB14 codes are translated from meta women\n",
      "MT10 codes are translated from meta women\n",
      "TA3 codes are translated from meta women\n",
      "CP2 codes are translated from meta women\n",
      "CM17 codes are translated from meta women\n",
      "MA6 codes are translated from meta women\n"
     ]
    }
   ],
   "source": [
    "p=process()\n",
    "p.process_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Non-smoker    9908\n",
       "Smoker        1061\n",
       "nan            329\n",
       "Missing        166\n",
       "Name: Smoker, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.data_wm['Smoker'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HH1</th>\n",
       "      <th>HH2</th>\n",
       "      <th>LN</th>\n",
       "      <th>WM1</th>\n",
       "      <th>WM2</th>\n",
       "      <th>WM3</th>\n",
       "      <th>WMINT</th>\n",
       "      <th>WM4</th>\n",
       "      <th>WM5</th>\n",
       "      <th>WM6D</th>\n",
       "      <th>WM6M</th>\n",
       "      <th>WM6Y</th>\n",
       "      <th>WM8</th>\n",
       "      <th>WM9</th>\n",
       "      <th>WM17</th>\n",
       "      <th>WM7H</th>\n",
       "      <th>WM7M</th>\n",
       "      <th>WM10H</th>\n",
       "      <th>WM10M</th>\n",
       "      <th>WM11</th>\n",
       "      <th>WMHINT</th>\n",
       "      <th>WMFIN</th>\n",
       "      <th>WB3M</th>\n",
       "      <th>WB3Y</th>\n",
       "      <th>WB4</th>\n",
       "      <th>WB5</th>\n",
       "      <th>WB6A</th>\n",
       "      <th>WB6B</th>\n",
       "      <th>WB7</th>\n",
       "      <th>WB9</th>\n",
       "      <th>WB10A</th>\n",
       "      <th>WB10B</th>\n",
       "      <th>WB11</th>\n",
       "      <th>WB12A</th>\n",
       "      <th>WB12B</th>\n",
       "      <th>WB14</th>\n",
       "      <th>WB15</th>\n",
       "      <th>WB16</th>\n",
       "      <th>WB17</th>\n",
       "      <th>WB18</th>\n",
       "      <th>WB19E</th>\n",
       "      <th>WB19F</th>\n",
       "      <th>WB19G</th>\n",
       "      <th>WB19H</th>\n",
       "      <th>WB19X</th>\n",
       "      <th>WB19NR</th>\n",
       "      <th>MT1</th>\n",
       "      <th>MT2</th>\n",
       "      <th>MT3</th>\n",
       "      <th>MT4</th>\n",
       "      <th>MT5</th>\n",
       "      <th>MT6A</th>\n",
       "      <th>MT6B</th>\n",
       "      <th>MT6C</th>\n",
       "      <th>MT6D</th>\n",
       "      <th>MT6E</th>\n",
       "      <th>MT6F</th>\n",
       "      <th>MT6G</th>\n",
       "      <th>MT6H</th>\n",
       "      <th>MT6I</th>\n",
       "      <th>MT9</th>\n",
       "      <th>MT10</th>\n",
       "      <th>MT11</th>\n",
       "      <th>MT12</th>\n",
       "      <th>CM1</th>\n",
       "      <th>CM2</th>\n",
       "      <th>CM3</th>\n",
       "      <th>CM4</th>\n",
       "      <th>CM5</th>\n",
       "      <th>CM6</th>\n",
       "      <th>CM7</th>\n",
       "      <th>CM8</th>\n",
       "      <th>CM9</th>\n",
       "      <th>CM10</th>\n",
       "      <th>CM11</th>\n",
       "      <th>CM12</th>\n",
       "      <th>CM15</th>\n",
       "      <th>CM17</th>\n",
       "      <th>BH11</th>\n",
       "      <th>DB2</th>\n",
       "      <th>DB4</th>\n",
       "      <th>MN2</th>\n",
       "      <th>MN3A</th>\n",
       "      <th>MN3B</th>\n",
       "      <th>MN3X</th>\n",
       "      <th>MN3NR</th>\n",
       "      <th>MN4AU</th>\n",
       "      <th>MN4AN</th>\n",
       "      <th>MN5</th>\n",
       "      <th>MN6A</th>\n",
       "      <th>MN6B</th>\n",
       "      <th>MN6C</th>\n",
       "      <th>MN19A</th>\n",
       "      <th>MN19B</th>\n",
       "      <th>MN19H</th>\n",
       "      <th>MN19X</th>\n",
       "      <th>MN19Y</th>\n",
       "      <th>MN19NR</th>\n",
       "      <th>MN20</th>\n",
       "      <th>MN21</th>\n",
       "      <th>MN22</th>\n",
       "      <th>MN23</th>\n",
       "      <th>MN24</th>\n",
       "      <th>MN25</th>\n",
       "      <th>MN26U</th>\n",
       "      <th>MN26N</th>\n",
       "      <th>MN32</th>\n",
       "      <th>MN33</th>\n",
       "      <th>MN34A</th>\n",
       "      <th>MN34</th>\n",
       "      <th>MN35</th>\n",
       "      <th>MN36</th>\n",
       "      <th>MN37U</th>\n",
       "      <th>MN37N</th>\n",
       "      <th>MN38</th>\n",
       "      <th>MN39A</th>\n",
       "      <th>MN39B</th>\n",
       "      <th>MN39C</th>\n",
       "      <th>MN39D</th>\n",
       "      <th>MN39E</th>\n",
       "      <th>MN39F</th>\n",
       "      <th>MN39G</th>\n",
       "      <th>MN39H</th>\n",
       "      <th>MN39I</th>\n",
       "      <th>MN39J</th>\n",
       "      <th>MN39X</th>\n",
       "      <th>MN39Y</th>\n",
       "      <th>MN39NR</th>\n",
       "      <th>PN3U</th>\n",
       "      <th>PN3N</th>\n",
       "      <th>PN4</th>\n",
       "      <th>PN5</th>\n",
       "      <th>PN6</th>\n",
       "      <th>PN8</th>\n",
       "      <th>PN9</th>\n",
       "      <th>PN10</th>\n",
       "      <th>PN11</th>\n",
       "      <th>PN12</th>\n",
       "      <th>PN13U</th>\n",
       "      <th>PN13N</th>\n",
       "      <th>PN14A</th>\n",
       "      <th>PN14B</th>\n",
       "      <th>PN14H</th>\n",
       "      <th>PN14X</th>\n",
       "      <th>PN14NR</th>\n",
       "      <th>PN15</th>\n",
       "      <th>PN17</th>\n",
       "      <th>PN19</th>\n",
       "      <th>PN20</th>\n",
       "      <th>PN21</th>\n",
       "      <th>PN22U</th>\n",
       "      <th>PN22N</th>\n",
       "      <th>PN23A</th>\n",
       "      <th>PN23B</th>\n",
       "      <th>PN23H</th>\n",
       "      <th>PN23X</th>\n",
       "      <th>PN23NR</th>\n",
       "      <th>PN24</th>\n",
       "      <th>PN25A</th>\n",
       "      <th>PN25B</th>\n",
       "      <th>PN25C</th>\n",
       "      <th>PN27</th>\n",
       "      <th>PN29</th>\n",
       "      <th>PN30</th>\n",
       "      <th>CP1</th>\n",
       "      <th>CP2</th>\n",
       "      <th>CP2A</th>\n",
       "      <th>CP3</th>\n",
       "      <th>CP4A</th>\n",
       "      <th>CP4B</th>\n",
       "      <th>CP4C</th>\n",
       "      <th>CP4D</th>\n",
       "      <th>CP4E</th>\n",
       "      <th>CP4F</th>\n",
       "      <th>CP4G</th>\n",
       "      <th>CP4H</th>\n",
       "      <th>CP4I</th>\n",
       "      <th>CP4J</th>\n",
       "      <th>CP4K</th>\n",
       "      <th>CP4L</th>\n",
       "      <th>CP4M</th>\n",
       "      <th>CP4X</th>\n",
       "      <th>CP4NR</th>\n",
       "      <th>UN2</th>\n",
       "      <th>UN4</th>\n",
       "      <th>UN5</th>\n",
       "      <th>UN7</th>\n",
       "      <th>UN8U</th>\n",
       "      <th>UN8N</th>\n",
       "      <th>UN11</th>\n",
       "      <th>UN12A</th>\n",
       "      <th>UN12B</th>\n",
       "      <th>UN12C</th>\n",
       "      <th>UN12D</th>\n",
       "      <th>UN12E</th>\n",
       "      <th>UN12F</th>\n",
       "      <th>UN12G</th>\n",
       "      <th>UN12H</th>\n",
       "      <th>UN12I</th>\n",
       "      <th>UN12X</th>\n",
       "      <th>UN12Z</th>\n",
       "      <th>UN12NR</th>\n",
       "      <th>UN14U</th>\n",
       "      <th>UN14N</th>\n",
       "      <th>UN16</th>\n",
       "      <th>UN17</th>\n",
       "      <th>UN18</th>\n",
       "      <th>UN19</th>\n",
       "      <th>DV1A</th>\n",
       "      <th>DV1B</th>\n",
       "      <th>DV1C</th>\n",
       "      <th>DV1D</th>\n",
       "      <th>DV1E</th>\n",
       "      <th>VT1</th>\n",
       "      <th>VT2</th>\n",
       "      <th>VT3</th>\n",
       "      <th>VT5</th>\n",
       "      <th>VT6</th>\n",
       "      <th>VT7A</th>\n",
       "      <th>VT7B</th>\n",
       "      <th>VT7X</th>\n",
       "      <th>VT7NR</th>\n",
       "      <th>VT8</th>\n",
       "      <th>VT9</th>\n",
       "      <th>VT10</th>\n",
       "      <th>VT11</th>\n",
       "      <th>VT12</th>\n",
       "      <th>VT13</th>\n",
       "      <th>VT14</th>\n",
       "      <th>VT17</th>\n",
       "      <th>VT18A</th>\n",
       "      <th>VT18B</th>\n",
       "      <th>VT18X</th>\n",
       "      <th>VT18NR</th>\n",
       "      <th>VT19</th>\n",
       "      <th>VT20</th>\n",
       "      <th>VT21</th>\n",
       "      <th>VT22A</th>\n",
       "      <th>VT22B</th>\n",
       "      <th>VT22D</th>\n",
       "      <th>VT22E</th>\n",
       "      <th>VT22F</th>\n",
       "      <th>VT22G</th>\n",
       "      <th>VT22H</th>\n",
       "      <th>VT22I</th>\n",
       "      <th>VT22X</th>\n",
       "      <th>MA1</th>\n",
       "      <th>MA2</th>\n",
       "      <th>MA3</th>\n",
       "      <th>MA4</th>\n",
       "      <th>MA5</th>\n",
       "      <th>MA6</th>\n",
       "      <th>MA7</th>\n",
       "      <th>MA8M</th>\n",
       "      <th>MA8Y</th>\n",
       "      <th>MA11</th>\n",
       "      <th>AF2</th>\n",
       "      <th>AF3</th>\n",
       "      <th>AF6</th>\n",
       "      <th>AF8</th>\n",
       "      <th>AF9</th>\n",
       "      <th>AF10</th>\n",
       "      <th>AF11</th>\n",
       "      <th>AF12</th>\n",
       "      <th>HA1</th>\n",
       "      <th>HA2</th>\n",
       "      <th>HA3</th>\n",
       "      <th>HA4</th>\n",
       "      <th>HA5</th>\n",
       "      <th>HA6</th>\n",
       "      <th>HA7</th>\n",
       "      <th>HA8A</th>\n",
       "      <th>HA8B</th>\n",
       "      <th>HA8C</th>\n",
       "      <th>HA10</th>\n",
       "      <th>HA13A</th>\n",
       "      <th>HA13B</th>\n",
       "      <th>HA13C</th>\n",
       "      <th>HA13D</th>\n",
       "      <th>HA30</th>\n",
       "      <th>HA31</th>\n",
       "      <th>HA32</th>\n",
       "      <th>HA33</th>\n",
       "      <th>HA34</th>\n",
       "      <th>HA35</th>\n",
       "      <th>HA36</th>\n",
       "      <th>TA1</th>\n",
       "      <th>TA2</th>\n",
       "      <th>TA3</th>\n",
       "      <th>TA4</th>\n",
       "      <th>TA5</th>\n",
       "      <th>TA6</th>\n",
       "      <th>TA7</th>\n",
       "      <th>TA8A</th>\n",
       "      <th>TA8B</th>\n",
       "      <th>TA8D</th>\n",
       "      <th>TA8X</th>\n",
       "      <th>TA8NR</th>\n",
       "      <th>TA9</th>\n",
       "      <th>TA10</th>\n",
       "      <th>TA11</th>\n",
       "      <th>TA12A</th>\n",
       "      <th>TA12B</th>\n",
       "      <th>TA12C</th>\n",
       "      <th>TA12D</th>\n",
       "      <th>TA12NR</th>\n",
       "      <th>TA12X</th>\n",
       "      <th>TA13</th>\n",
       "      <th>LS1</th>\n",
       "      <th>LS2</th>\n",
       "      <th>LS3</th>\n",
       "      <th>LS4</th>\n",
       "      <th>HH4</th>\n",
       "      <th>HH6</th>\n",
       "      <th>HH7</th>\n",
       "      <th>REGION</th>\n",
       "      <th>WDOI</th>\n",
       "      <th>WAGE</th>\n",
       "      <th>WDOB</th>\n",
       "      <th>WDOM</th>\n",
       "      <th>WAGEM</th>\n",
       "      <th>WDOBFC</th>\n",
       "      <th>WDOBLC</th>\n",
       "      <th>MSTATUS</th>\n",
       "      <th>CEB</th>\n",
       "      <th>CSURV</th>\n",
       "      <th>CDEAD</th>\n",
       "      <th>BH3_FIRST</th>\n",
       "      <th>BH4M_FIRST</th>\n",
       "      <th>BH4Y_FIRST</th>\n",
       "      <th>BH6_FIRST</th>\n",
       "      <th>BH3_LAST</th>\n",
       "      <th>BH4M_LAST</th>\n",
       "      <th>BH4Y_LAST</th>\n",
       "      <th>BH6_LAST</th>\n",
       "      <th>welevel</th>\n",
       "      <th>insurance</th>\n",
       "      <th>disability</th>\n",
       "      <th>Refugee</th>\n",
       "      <th>wmweight</th>\n",
       "      <th>wscore</th>\n",
       "      <th>windex5</th>\n",
       "      <th>windex10</th>\n",
       "      <th>wscoreu</th>\n",
       "      <th>windex5u</th>\n",
       "      <th>windex10u</th>\n",
       "      <th>wscorer</th>\n",
       "      <th>windex5r</th>\n",
       "      <th>windex10r</th>\n",
       "      <th>wscorec</th>\n",
       "      <th>windex5c</th>\n",
       "      <th>windex10c</th>\n",
       "      <th>J1</th>\n",
       "      <th>PSU</th>\n",
       "      <th>stratum</th>\n",
       "      <th>nat_reg_lvl</th>\n",
       "      <th>disability_combined</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>Literacy</th>\n",
       "      <th>edu_level</th>\n",
       "      <th>Birth_Skilled_Per</th>\n",
       "      <th>modern_contraceptive</th>\n",
       "      <th>HC14</th>\n",
       "      <th>HL1</th>\n",
       "      <th>hh_size</th>\n",
       "      <th>HL3</th>\n",
       "      <th>HL6</th>\n",
       "      <th>hh_type</th>\n",
       "      <th>living_alone</th>\n",
       "      <th>agegrp4_1</th>\n",
       "      <th>agegrp4_2</th>\n",
       "      <th>agegrp10</th>\n",
       "      <th>agegrp15</th>\n",
       "      <th>agegrp5p</th>\n",
       "      <th>agegrp15p</th>\n",
       "      <th>agegrp25p</th>\n",
       "      <th>agegrp5</th>\n",
       "      <th>agegrp_9</th>\n",
       "      <th>age_ict</th>\n",
       "      <th>agegrp18p</th>\n",
       "      <th>hh_rel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3478</th>\n",
       "      <td>138.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>303.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1980.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>YES</td>\n",
       "      <td>BASIC</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>E</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AT LEAST ONCE A WEEK</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NO LIVE BIRTHS IN THE LAST 2 YEARS</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NO</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>X</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1996.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>YES</td>\n",
       "      <td>20.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>303.0</td>\n",
       "      <td>URBAN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>35-39</td>\n",
       "      <td>962.0</td>\n",
       "      <td>1160.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1180.0</td>\n",
       "      <td>1369.0</td>\n",
       "      <td>Currently married/in union</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Has no functional difficulty</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.213778</td>\n",
       "      <td>0.256939</td>\n",
       "      <td>Middle</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.279749</td>\n",
       "      <td>Middle</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>No difficulty</td>\n",
       "      <td>Missing</td>\n",
       "      <td>Literate</td>\n",
       "      <td>ISCED 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>OWN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>Nuclear</td>\n",
       "      <td>not alone</td>\n",
       "      <td>30+</td>\n",
       "      <td>25-64</td>\n",
       "      <td>25-64</td>\n",
       "      <td>30-44</td>\n",
       "      <td>5+</td>\n",
       "      <td>15+</td>\n",
       "      <td>25+</td>\n",
       "      <td>35-39</td>\n",
       "      <td>25-64</td>\n",
       "      <td>15-60</td>\n",
       "      <td>18+</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3479</th>\n",
       "      <td>138.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>303.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>YES</td>\n",
       "      <td>HIGHER</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>E</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ALMOST EVERY DAY</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>303.0</td>\n",
       "      <td>URBAN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>20-24</td>\n",
       "      <td>1180.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Never married/in union</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Has no functional difficulty</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.213778</td>\n",
       "      <td>0.256939</td>\n",
       "      <td>Middle</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.279749</td>\n",
       "      <td>Middle</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Some difficulty</td>\n",
       "      <td>Missing</td>\n",
       "      <td>Literate</td>\n",
       "      <td>ISCED 6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No</td>\n",
       "      <td>OWN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Nuclear</td>\n",
       "      <td>not alone</td>\n",
       "      <td>20-24</td>\n",
       "      <td>20-24</td>\n",
       "      <td>15-24</td>\n",
       "      <td>15-29</td>\n",
       "      <td>5+</td>\n",
       "      <td>15+</td>\n",
       "      <td>&lt;25</td>\n",
       "      <td>20-24</td>\n",
       "      <td>18-24</td>\n",
       "      <td>15-60</td>\n",
       "      <td>18+</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        HH1   HH2   LN    WM1   WM2  WM3  WMINT    WM4    WM5  WM6D  WM6M  \\\n",
       "3478  138.0  21.0  2.0  138.0  21.0  2.0  170.0  303.0  170.0  31.0  12.0   \n",
       "3479  138.0  21.0  3.0  138.0  21.0  3.0  170.0  303.0  170.0  31.0  12.0   \n",
       "\n",
       "        WM6Y  WM8  WM9  WM17  WM7H  WM7M  WM10H  WM10M  WM11  WMHINT  WMFIN  \\\n",
       "3478  2019.0  2.0  1.0   1.0  13.0   5.0   13.0   23.0   1.0   170.0    3.0   \n",
       "3479  2019.0  2.0  1.0   1.0  13.0  36.0   13.0   41.0   1.0   170.0    3.0   \n",
       "\n",
       "      WB3M    WB3Y   WB4  WB5    WB6A  WB6B  WB7  WB9  WB10A  WB10B  WB11  \\\n",
       "3478   2.0  1980.0  39.0  YES   BASIC  10.0  1.0  NaN    NaN    NaN   NaN   \n",
       "3479   4.0  1998.0  21.0  YES  HIGHER   4.0  2.0  1.0    3.0    4.0   1.0   \n",
       "\n",
       "      WB12A  WB12B WB14  WB15  WB16  WB17  WB18 WB19E WB19F WB19G WB19H WB19X  \\\n",
       "3478    NaN    NaN  NaN  23.0   9.0  30.0   1.0     E                           \n",
       "3479    3.0    3.0  NaN  95.0   NaN   NaN   1.0     E                           \n",
       "\n",
       "     WB19NR  MT1  MT2  MT3  MT4  MT5  MT6A  MT6B  MT6C  MT6D  MT6E  MT6F  \\\n",
       "3478         0.0  1.0  3.0  1.0  1.0   2.0   2.0   1.0   2.0   2.0   2.0   \n",
       "3479         0.0  3.0  9.0  1.0  3.0   1.0   2.0   1.0   1.0   1.0   1.0   \n",
       "\n",
       "      MT6G  MT6H  MT6I  MT9                  MT10  MT11  MT12  CM1  CM2  CM3  \\\n",
       "3478   2.0   2.0   1.0  NaN  AT LEAST ONCE A WEEK   1.0   3.0  1.0  1.0  2.0   \n",
       "3479   2.0   1.0   2.0  NaN      ALMOST EVERY DAY   1.0   3.0  NaN  NaN  NaN   \n",
       "\n",
       "      CM4  CM5  CM6  CM7  CM8  CM9  CM10  CM11  CM12  CM15  \\\n",
       "3478  2.0  2.0  NaN  NaN  2.0  NaN   NaN   4.0   1.0   1.0   \n",
       "3479  NaN  NaN  NaN  NaN  NaN  NaN   NaN   NaN   NaN   NaN   \n",
       "\n",
       "                                    CM17  BH11  DB2  DB4  MN2 MN3A MN3B MN3X  \\\n",
       "3478  NO LIVE BIRTHS IN THE LAST 2 YEARS   2.0  NaN  NaN  NaN                  \n",
       "3479                                 NaN   NaN  NaN  NaN  NaN                  \n",
       "\n",
       "     MN3NR  MN4AU  MN4AN  MN5  MN6A  MN6B  MN6C MN19A MN19B MN19H MN19X MN19Y  \\\n",
       "3478          NaN    NaN  NaN   NaN   NaN   NaN                                 \n",
       "3479          NaN    NaN  NaN   NaN   NaN   NaN                                 \n",
       "\n",
       "     MN19NR  MN20  MN21  MN22  MN23  MN24  MN25  MN26U  MN26N  MN32  MN33  \\\n",
       "3478          NaN   NaN   NaN   NaN   NaN   NaN    NaN    NaN   NaN   NaN   \n",
       "3479          NaN   NaN   NaN   NaN   NaN   NaN    NaN    NaN   NaN   NaN   \n",
       "\n",
       "      MN34A  MN34  MN35  MN36  MN37U  MN37N  MN38 MN39A MN39B MN39C MN39D  \\\n",
       "3478    NaN   NaN   NaN   NaN    NaN    NaN   NaN                           \n",
       "3479    NaN   NaN   NaN   NaN    NaN    NaN   NaN                           \n",
       "\n",
       "     MN39E MN39F MN39G MN39H MN39I MN39J MN39X MN39Y MN39NR  PN3U  PN3N  PN4  \\\n",
       "3478                                                          NaN   NaN  NaN   \n",
       "3479                                                          NaN   NaN  NaN   \n",
       "\n",
       "      PN5  PN6  PN8  PN9  PN10  PN11  PN12  PN13U  PN13N PN14A PN14B PN14H  \\\n",
       "3478  NaN  NaN  NaN  NaN   NaN   NaN   NaN    NaN    NaN                     \n",
       "3479  NaN  NaN  NaN  NaN   NaN   NaN   NaN    NaN    NaN                     \n",
       "\n",
       "     PN14X PN14NR  PN15  PN17  PN19  PN20  PN21  PN22U  PN22N PN23A PN23B  \\\n",
       "3478                NaN   NaN   NaN   NaN   NaN    NaN    NaN               \n",
       "3479                NaN   NaN   NaN   NaN   NaN    NaN    NaN               \n",
       "\n",
       "     PN23H PN23X PN23NR  PN24  PN25A  PN25B  PN25C  PN27  PN29  PN30  CP1  \\\n",
       "3478                      NaN    NaN    NaN    NaN   NaN   NaN   NaN  2.0   \n",
       "3479                      NaN    NaN    NaN    NaN   NaN   NaN   NaN  NaN   \n",
       "\n",
       "      CP2  CP2A  CP3 CP4A CP4B CP4C CP4D CP4E CP4F CP4G CP4H CP4I CP4J CP4K  \\\n",
       "3478   NO  23.0  2.0                                                          \n",
       "3479  NaN   NaN  NaN                                                          \n",
       "\n",
       "     CP4L CP4M CP4X CP4NR  UN2  UN4  UN5  UN7  UN8U  UN8N  UN11 UN12A UN12B  \\\n",
       "3478                       NaN  NaN  NaN  2.0   NaN   NaN   2.0               \n",
       "3479                       NaN  NaN  NaN  NaN   NaN   NaN   NaN               \n",
       "\n",
       "     UN12C UN12D UN12E UN12F UN12G UN12H UN12I UN12X UN12Z UN12NR  UN14U  \\\n",
       "3478                                               X                 2.0   \n",
       "3479                                                                 NaN   \n",
       "\n",
       "      UN14N  UN16  UN17  UN18  UN19  DV1A  DV1B  DV1C  DV1D  DV1E  VT1  VT2  \\\n",
       "3478   99.0   NaN   NaN   NaN   NaN   2.0   2.0   2.0   2.0   2.0  2.0  NaN   \n",
       "3479    NaN   NaN   NaN   NaN   NaN   2.0   2.0   2.0   2.0   2.0  2.0  NaN   \n",
       "\n",
       "      VT3  VT5  VT6 VT7A VT7B VT7X VT7NR  VT8  VT9  VT10  VT11  VT12  VT13  \\\n",
       "3478  NaN  NaN  NaN                       NaN  2.0   NaN   NaN   NaN   NaN   \n",
       "3479  NaN  NaN  NaN                       NaN  2.0   NaN   NaN   NaN   NaN   \n",
       "\n",
       "      VT14  VT17 VT18A VT18B VT18X VT18NR  VT19  VT20  VT21  VT22A  VT22B  \\\n",
       "3478   NaN   NaN                            NaN   2.0   2.0    2.0    2.0   \n",
       "3479   NaN   NaN                            NaN   2.0   2.0    2.0    2.0   \n",
       "\n",
       "      VT22D  VT22E  VT22F  VT22G  VT22H  VT22I  VT22X  MA1   MA2  MA3  MA4  \\\n",
       "3478    2.0    2.0    2.0    2.0    2.0    2.0    2.0  1.0  16.0  2.0  NaN   \n",
       "3479    2.0    2.0    2.0    2.0    2.0    2.0    2.0  3.0   NaN  NaN  NaN   \n",
       "\n",
       "      MA5  MA6  MA7  MA8M    MA8Y  MA11  AF2  AF3  AF6  AF8  AF9  AF10  AF11  \\\n",
       "3478  NaN  NaN  1.0   8.0  1996.0   NaN  2.0  2.0  1.0  1.0  1.0   1.0   1.0   \n",
       "3479  3.0  NaN  NaN   NaN     NaN   NaN  2.0  2.0  2.0  1.0  1.0   1.0   1.0   \n",
       "\n",
       "      AF12  HA1  HA2  HA3  HA4  HA5  HA6  HA7  HA8A  HA8B  HA8C  HA10  HA13A  \\\n",
       "3478   1.0  1.0  1.0  2.0  1.0  2.0  1.0  1.0   1.0   1.0   1.0   2.0    NaN   \n",
       "3479   1.0  1.0  8.0  1.0  1.0  2.0  2.0  8.0   1.0   1.0   1.0   1.0    NaN   \n",
       "\n",
       "      HA13B  HA13C  HA13D  HA30  HA31  HA32  HA33  HA34  HA35  HA36  TA1  \\\n",
       "3478    NaN    NaN    NaN   1.0   2.0   2.0   1.0   2.0   1.0   1.0  1.0   \n",
       "3479    NaN    NaN    NaN   2.0   2.0   2.0   2.0   2.0   1.0   1.0  2.0   \n",
       "\n",
       "       TA2  TA3   TA4   TA5  TA6  TA7 TA8A TA8B TA8D TA8X TA8NR  TA9  TA10  \\\n",
       "3478  13.0  YES  20.0  30.0  2.0  NaN                            NaN   9.0   \n",
       "3479   NaN  NaN   NaN   NaN  2.0  NaN                            NaN   9.0   \n",
       "\n",
       "      TA11 TA12A TA12B TA12C TA12D TA12NR TA12X  TA13  LS1  LS2  LS3  LS4  \\\n",
       "3478   NaN                                        NaN  2.0  8.0  2.0  2.0   \n",
       "3479   NaN                                        NaN  1.0  9.0  1.0  1.0   \n",
       "\n",
       "        HH4    HH6   HH7  REGION    WDOI   WAGE    WDOB    WDOM  WAGEM  \\\n",
       "3478  303.0  URBAN  30.0     1.0  1440.0  35-39   962.0  1160.0   16.0   \n",
       "3479  303.0  URBAN  30.0     1.0  1440.0  20-24  1180.0     NaN    NaN   \n",
       "\n",
       "      WDOBFC  WDOBLC                     MSTATUS  CEB  CSURV  CDEAD  \\\n",
       "3478  1180.0  1369.0  Currently married/in union  4.0    4.0    0.0   \n",
       "3479     NaN     NaN      Never married/in union  0.0    0.0    0.0   \n",
       "\n",
       "      BH3_FIRST  BH4M_FIRST  BH4Y_FIRST  BH6_FIRST  BH3_LAST  BH4M_LAST  \\\n",
       "3478        2.0         4.0      1998.0       21.0       2.0        1.0   \n",
       "3479        NaN         NaN         NaN        NaN       NaN        NaN   \n",
       "\n",
       "      BH4Y_LAST  BH6_LAST  welevel  insurance                    disability  \\\n",
       "3478     2014.0       5.0      1.0        1.0  Has no functional difficulty   \n",
       "3479        NaN       NaN      3.0        1.0  Has no functional difficulty   \n",
       "\n",
       "      Refugee  wmweight    wscore windex5  windex10   wscoreu windex5u  \\\n",
       "3478      1.0  1.213778  0.256939  Middle       5.0  0.279749   Middle   \n",
       "3479      1.0  1.213778  0.256939  Middle       5.0  0.279749   Middle   \n",
       "\n",
       "      windex10u  wscorer windex5r  windex10r  wscorec  windex5c  windex10c  \\\n",
       "3478        6.0      NaN      NaN        NaN      NaN       NaN        NaN   \n",
       "3479        6.0      NaN      NaN        NaN      NaN       NaN        NaN   \n",
       "\n",
       "       J1    PSU  stratum  nat_reg_lvl disability_combined   Smoker  Literacy  \\\n",
       "3478  2.0  138.0     17.0          2.0       No difficulty  Missing  Literate   \n",
       "3479  2.0  138.0     17.0          2.0     Some difficulty  Missing  Literate   \n",
       "\n",
       "     edu_level Birth_Skilled_Per modern_contraceptive HC14  HL1 hh_size  HL3  \\\n",
       "3478   ISCED 1               NaN                   No  OWN  2.0     6.0  2.0   \n",
       "3479   ISCED 6               NaN                   No  OWN  3.0     6.0  3.0   \n",
       "\n",
       "       HL6  hh_type living_alone agegrp4_1 agegrp4_2 agegrp10 agegrp15  \\\n",
       "3478  39.0  Nuclear    not alone       30+     25-64    25-64    30-44   \n",
       "3479  21.0  Nuclear    not alone     20-24     20-24    15-24    15-29   \n",
       "\n",
       "     agegrp5p agegrp15p agegrp25p agegrp5 agegrp_9 age_ict agegrp18p hh_rel  \n",
       "3478       5+       15+       25+   35-39    25-64   15-60       18+  Other  \n",
       "3479       5+       15+       <25   20-24    18-24   15-60       18+  Other  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.data_wm[(p.data_wm['HH1']==138)& (p.data_wm['HH2']==21)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class crosstab(process):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.data_wm=p.data_wm\n",
    "        self.data_hh=p.data_hh\n",
    "        self.data_hl=p.data_hl\n",
    "        \n",
    "\n",
    "    def generate_xtabs(self):\n",
    "        os.chdir('C:/Users/511232/Desktop/MICS/Crosstabs')\n",
    "        \n",
    "        try:\n",
    "            '''Table 1:Total population, by sex, age, location and disability status\n",
    "            'disability_combined' column is calculated by taking the max(code) among ['AF6','AF8','AF9','AF10','AF11','AF12']\n",
    "            '''\n",
    "            print('generating Table 1')\n",
    "            df=self.data_wm.copy()\n",
    "            df_total=[]\n",
    "            for col in ['WAGE', 'agegrp18p']:\n",
    "                xtab=pd.crosstab([df['HH6'],df['disability_combined']],df[col],\n",
    "                rownames=['Area','Disability level'],colnames=[col], values=df['wmweight'], aggfunc='sum',dropna=False)\n",
    "                df_total.append(xtab)\n",
    "            T=pd.concat(df_total, axis=1)     \n",
    "            T.to_excel('Table 1 xtab_all_dis_ByAge.xlsx')\n",
    "            print('Table 1 generated and saved')\n",
    "            ###########################################################\n",
    "\n",
    "            '''Table 2:Persons with disabilities, by type of disability,  sex, age and location\n",
    "            -generate separate xtabs for all disability_cols\n",
    "            -stack() them to have a multiindex series and add them to a generator\n",
    "            -concatenate the generator items\n",
    "            -stack() and unstack() to get to the final result \n",
    "            '''\n",
    "            print('generating Table 2')\n",
    "            df=self.data_wm.copy()\n",
    "            df_total=[]\n",
    "            def xtab():\n",
    "                for col in self.disability_cols:\n",
    "                    print(f'processing column {col}')\n",
    "                    r=pd.crosstab([df['HH6'],df[col].map(self.disability_levels)],df['WAGE'],\\\n",
    "                        rownames=['Area','Level'],colnames=['Age'], values=df['wmweight'], \n",
    "                        aggfunc='sum',dropna=False).stack()\n",
    "                    r.name=self.dis_names[col]\n",
    "                    df_total.append(r)\n",
    "\n",
    "            #concatenating the series in the resulting generator\n",
    "            xtab()\n",
    "            t=pd.concat(df_total, axis=1)\n",
    "            t['All_disabilities']=t.sum(axis=1)\n",
    "            #reshape the result\n",
    "            T=t.stack().unstack([3,2]).sort_index(axis=1, level=0)\n",
    "            T.to_excel('Table 2 separate disabilites.xlsx')\n",
    "            print('Table 2 generated and saved')\n",
    "\n",
    "            ###############################################################\n",
    "            '''Table 3: Persons with disabilities, by cause of disability, sex and location\n",
    "            rows: cause of disability ??????????????????????\n",
    "            columns: disability, HH6 area\n",
    "            '''\n",
    "            print('WARNING !!! Table 3 cause of disability not found')\n",
    "            df=self.data_wm.copy()\n",
    "\n",
    "            ###############################################################\n",
    "            '''Table 4 (VERIFIED): Persons with multi-dimensional disability, by number of functional disability domains, sex and location\n",
    "            -calculate domain_num by summing the True over the array of disability_cols values\n",
    "            if the array contains codes (3-a lot of difficulty) or (4-cannot at all) it will result as True\n",
    "            '''\n",
    "            print('generating Table 4')\n",
    "            df=self.data_wm.copy()\n",
    "            df['domain_num']=df[self.disability_cols].apply(lambda x: sum(x.isin([3,4])), axis=1)\n",
    "            #generate xtab\n",
    "            r=pd.crosstab([df['HH6'],df['disability_combined']],df['domain_num'],\\\n",
    "                rownames=['Area','Disability'],colnames=['Number of domains'], values=df['wmweight'], aggfunc='sum', dropna=False)\n",
    "            \n",
    "            r.to_excel('Table 4 Number_dis_domain.xlsx')\n",
    "            print('Table 4 generated and saved')\n",
    "\n",
    "            #################################################################\n",
    "            '''Table 5 (VERIFIED) marital status: Population (15 years and older) marital status, by sex, age, location and disability status'''\n",
    "            print('generating Table 5')\n",
    "            df=self.data_wm.copy()\n",
    "            xtab=pd.crosstab([df['HH6'],df['MSTATUS'],df['MA6'],df['disability_combined']],df['WAGE'],\n",
    "            rownames=['Area','Marital status','Current marital status','Disability level'],\n",
    "            colnames=['Age'], values=df['wmweight'],aggfunc='sum',dropna=False)      \n",
    "\n",
    "            xtab.to_excel('Table 5 MaritalStatus.xlsx')\n",
    "            print('Table 5 generated and saved')\n",
    "\n",
    "            ###############################################################\n",
    "            '''Table 6 head_HH: Head of household living below the national poverty line and by wealth quintile, \n",
    "            sex of head of household, location and disability  status\n",
    "            1-disability against head of household and othery type of relationship\n",
    "            -create head of household relationship (in the self_data_wm() )\n",
    "            df['hh_rel']=np.where(df['HL3']==1,1,2) where 1:HH 2:Other \n",
    "            2-disability by head of households by wealth quintiles\n",
    "            -will generate crosstab among disabled HH with wealth quintiles \n",
    "            using windex and not specific windex5u for urban and windex5r for rural since\n",
    "            they differ from windex5 and will produce contradictory results between urban and rural xtabs\n",
    "            and the urban and rural disaggregation in the xtab for the total: camp/urban/rural\n",
    "            '''\n",
    "\n",
    "            #crosstab 1\n",
    "            print('generating Table 6.1')\n",
    "            df=self.data_wm.copy()\n",
    "            xtab=pd.crosstab([df['HH6'],df['disability_combined']],df['hh_rel'],\n",
    "            rownames=['Area','Disability level'],colnames=['HH relationship'], values=df['wmweight'],\n",
    "            aggfunc='sum',dropna=False)\n",
    "            xtab.to_excel('Table 6.1 head of HH.xlsx')\n",
    "            print('Table 6.1 generated and saved')\n",
    "            \n",
    "            #crosstab 2\n",
    "            #filter out the HH\n",
    "            print('generating Table 6.2')\n",
    "            df_hh_only=df[df['hh_rel']=='Head of household']\n",
    "            xtab=pd.crosstab([df_hh_only['HH6'],df_hh_only['disability_combined']],df_hh_only['windex5'],\n",
    "            rownames=['Area','Disability level'],colnames=['wealth quintile'], values=df_hh_only['wmweight'],\n",
    "            aggfunc='sum',dropna=False)\n",
    "            xtab.to_excel('Table 6.2 head of HH_with wquintile.xlsx')\n",
    "            print('Table 6.2 generated and saved')\n",
    "\n",
    "            ############################################################################\n",
    "            '''Table 7 (VERIFIED) Poorest_type: Poorest persons with disabilities, by type of disability, sex and location\n",
    "            -filter out the poorest quintile 'windex5' and crosstab with all disability types\n",
    "            -loop over disability_cols and create crosstabs then stack to end up with multiindex series\n",
    "            -put them in a generator and concatenate the generator items\n",
    "            '''\n",
    "            print('generating Table 7')\n",
    "            df=self.data_wm.copy()\n",
    "            #filter out the poorest\n",
    "            df_poorest=df[df['windex5']=='Poorest'].copy()\n",
    "            df_total=[]\n",
    "            for col in self.disability_cols:\n",
    "                print(f'selfing column {col}')\n",
    "                r=pd.crosstab([df_poorest['HH6']],df_poorest[col].map(self.disability_levels),\\\n",
    "                    rownames=['Area'],colnames=['Disability level'], \n",
    "                    values=df_poorest['wmweight'], aggfunc='sum',dropna=False).stack()\n",
    "                r.name=self.dis_names[col]\n",
    "                df_total.append(r)\n",
    "\n",
    "            #concatenating the series in the resulting generator\n",
    "            t=pd.concat(df_total, axis=1)\n",
    "            t['All_disabilities']=t.sum(axis=1)\n",
    "            t.to_excel('Table 7 poorest_type.xlsx')\n",
    "            print('Table 7 generated and saved')\n",
    "\n",
    "            ###########################################################\n",
    "            '''Table 8 HH_type&size:\n",
    "            Households with one or more persons with disabilities (18 years and older), by location and type and size of household\n",
    "            -data_wm will be filtered according to (age>=18 & disability_combined==3,4) \n",
    "            -get the 'HH1','HH2' of the resulting dataframe as a list by zipping both columns\n",
    "            -filter data resulting from  self_data_wm() on the tuple ('HH1','HH2')\n",
    "\n",
    "            steps for calculating type of household hh_type (in hl dataframe):\n",
    "            -grouby hl by ['HH1','HH2']\n",
    "            -if HL3 isin (1 head,2 spouse/partner,3 son/daughter,13 adopted son daughter)\n",
    "            if ALL TRUE then code hh_type as 1 Nuclear\n",
    "            -if HL3 isin (1 head,2 spouse/partner,3 son/daughter,13 adopted son daughter,\n",
    "            4 son /daughter in law, 5 grnachild, 6 parent, 7 parentin law, 8 brother/sister,\n",
    "            9, brother/sis in law, 10 uncle/aunt, 11 nephew/niece, 12 other)\n",
    "            if ALL TRUE then code hh_type as 2 Extended\n",
    "            if HL3 isin (1 head,2 spouse/partner,3 son/daughter,13 adopted son daughter,\n",
    "            4 son /daughter in law, 5 grandchild, 6 parent, 7 parent in law, 8 brother/sister,\n",
    "            9, brother/sis in law, 10 uncle/aunt, 11 nephew/niece, 12 other, 14 servant, 96 other, 98 dont know)\n",
    "            if ALL TRUE then code hh_type as 3 composite\n",
    "            WARNING: there is no way to distinguish two nuclear families in a single household from one\n",
    "            since for example a HH might have 2 spouses or more \n",
    "            -data_wm with merge hl left_on=['HH1','HH2','LN'], right_on=['HH1','HH2','HL1'])\n",
    "            to get the hh_type variable\n",
    "            -perform corsstab\n",
    "            '''\n",
    "            print('generating Table 8')\n",
    "            df=self.data_wm.copy()\n",
    "            #criteria 1 for being disabled, and criteria 2 for being >=18\n",
    "            criteria1=((df['disability_combined']=='Cannot do at all')|(df['disability_combined']=='A lot of difficulty'))\n",
    "            criteria2=(df['HL6']>=18)\n",
    "\n",
    "            #filter according to criteria1 & criteria2\n",
    "            df_filtered=df.loc[criteria1 & criteria2, ['HH1','HH2']].drop_duplicates()\n",
    "            # filter df_w according to resulting ['HH1','HH2']\n",
    "            hhd_filter=pd.Series(zip(df['HH1'],df['HH2'])).isin(list(zip(df_filtered['HH1'],df_filtered['HH2'])))\n",
    "            #filter according to tuple ('HH1','HH2')\n",
    "            df_wm_filtered=df[hhd_filter]\n",
    "            \n",
    "            #generate the crosstab\n",
    "            xtab=pd.crosstab([df_wm_filtered['HH6'],df_wm_filtered['hh_type']],\n",
    "            [df_wm_filtered['disability_combined']],\n",
    "            rownames=['Area','Household type'],colnames=['Disability level'], values=df_wm_filtered['wmweight'],\n",
    "            aggfunc='sum',dropna=False)\n",
    "            xtab.to_excel('Table 8.1 hh_type_size1.xlsx')\n",
    "            print('Table 8.1 generated and saved')\n",
    "\n",
    "            xtab=pd.crosstab([df_wm_filtered['HH6'],df_wm_filtered['hh_type']],df_wm_filtered['hh_size'],\n",
    "            rownames=['Area','Household type'],colnames=['Household size'], values=df_wm_filtered['wmweight'],\n",
    "            aggfunc='sum',dropna=False)\n",
    "            xtab.to_excel('Table 8.2 hh_type_size2.xlsx')\n",
    "            print('Table 8.2 generated and saved')\n",
    "\n",
    "            ########################################\n",
    "            '''Table 9 living_type_age:\n",
    "            Persons with disabilities living in household or in institution, by type of disability, sex, age and location\n",
    "            rows: location(HH6), living_alone, hhd_inst (living alone, living with a family in hhd, living in institution)\n",
    "            note: Palestine doesnt have a question for place of hh whether institution or not so in this case\n",
    "            the hh_size is being used as alone versus not alone), disability (filter on disabled), disability combined\n",
    "            columns: separate disabilities (that is on ['AF6','AF8','AF9','AF10','AF11','AF12']), agegroups (WAGE)'''\n",
    "            \n",
    "            df=self.data_wm.copy()\n",
    "            #criteria 1 for being disabled, and criteria 2 for being >=18\n",
    "            criteria=((df['disability_combined']=='Cannot do at all')|(df['disability_combined']=='A lot of difficulty'))\n",
    "\n",
    "            #filter according to criteria1 & criteria2\n",
    "            df_filtered=df[criteria].copy()\n",
    "            df_total=[]\n",
    "\n",
    "            for col in self.disability_cols:\n",
    "                df_filtered[col]=df_filtered[col].map(self.disability_levels)\n",
    "                print(f'processing column {col}')\n",
    "                #generate the crosstab\n",
    "                r=pd.crosstab([df_filtered['HH6'],df_filtered['living_alone'],\n",
    "                df_filtered[col]],[df_filtered['agegrp_9']],\n",
    "                rownames=['Area','Living alone','Disability level'],colnames=['Age group'], values=df_filtered['wmweight'],\n",
    "                aggfunc='sum',dropna=False).stack()\n",
    "                r.name=self.dis_names[col]\n",
    "                df_total.append(r)\n",
    "\n",
    "            #concatenating the series in the resulting generator\n",
    "            t=pd.concat(df_total, axis=1)\n",
    "\n",
    "            #reshape the result\n",
    "            T=t.unstack([3]).sort_index(axis=1, level=0)\n",
    "            T.to_excel('Table 9 living_type_age.xlsx')\n",
    "            print('Table 9 generated and saved')\n",
    "\n",
    "            ####################################################\n",
    "            '''Table 10 (VERIFIED) house_ownership: \n",
    "            House ownership of population (18 years and older) living alone, by sex, location and disability status\n",
    "            filter data_wm on 'living_alone' and HL6>=18\n",
    "            Rows: location (HH6), disability (disability), disability combined\n",
    "            columns: house ownership (HC14: {1.0: 'OWN', 2.0: 'RENT', 6.0: 'OTHER', 9.0: 'NO RESPONSE'})'''\n",
    "            \n",
    "            print('generating Table 10')\n",
    "            df=self.data_wm.copy()\n",
    "\n",
    "            criteria=((df['HL6']>=18)&(df['living_alone']=='alone'))\n",
    "            #filter according to criteria1 & criteria2\n",
    "            df_filtered=df[criteria].copy()\n",
    "\n",
    "            #crosstab\n",
    "            r=pd.crosstab([df_filtered['HH6'],df_filtered['disability_combined']],\n",
    "            [df_filtered['HC14']],\n",
    "            rownames=['Area','Disability level'],colnames=['house ownership'], values=df_filtered['wmweight'],\n",
    "            aggfunc='sum',dropna=False)\n",
    "            r['Total 18+']=r.sum(axis=1)\n",
    "\n",
    "            r.to_excel('Table 10 house_ownership.xlsx')\n",
    "            print('Table 10 generated and saved')\n",
    "\n",
    "            #######################################################\n",
    "            '''Table 11: Education attainment of population (5 years and older), by sex, age, location and disability status \n",
    "            recode HL6 to age_5, to age_15, to age_25\n",
    "            recode HL6 into age_bounded 15-29, 30-44, 45-64, 65+\n",
    "            filter data_wm by HL6>=5\n",
    "            rows: location (HH6), disability (disability), disability combined\n",
    "            columns: Edu attainment (WB6A), agegroups\n",
    "            '''\n",
    "            print('generating Table 11')\n",
    "            df=self.data_wm.copy()\n",
    "            df_filtered=df[df['HL6']>=5].copy()\n",
    "\n",
    "            def xtab():\n",
    "                for col in ['agegrp5p','agegrp15p','agegrp25p','agegrp15']:\n",
    "                    #for agegrp5p age 5+\n",
    "                    r=pd.crosstab([df_filtered['HH6'],df_filtered['disability_combined']],\n",
    "                    [df_filtered['edu_level'],df_filtered[col]],\n",
    "                    rownames=['Area','Disability level'],colnames=['Edu attainment','Age'], values=df_filtered['wmweight'],\n",
    "                    aggfunc='sum',dropna=False).stack().stack()\n",
    "                    r.name=col\n",
    "                    yield(r)\n",
    "\n",
    "            #concatenating the series in the resulting generator\n",
    "            s=xtab()\n",
    "            t=pd.concat(s, axis=1)\n",
    "\n",
    "            #reshape the result\n",
    "            T=t.unstack([3,2]).sort_index(axis=1, level=0)\n",
    "            T.to_excel('Table 11 living_type_age.xlsx')\n",
    "            print('Table 11 generated and saved')\n",
    "        \n",
    "            #######################################################\n",
    "            '''Table 12: Education attainment of persons with disabilities (5 years and older), by type of disability, sex, age and location\n",
    "            filter on age 'HL6']>=5\n",
    "            rows: ['Area' (HH6),'Disability','Disability level']\n",
    "            cols: ['Edu attainment' (WB6A),'Age']\n",
    "            create a new column = disability_cols values\n",
    "            loop over ['agegrp5p','agegrp15p','agegrp25p'] and yield the result\n",
    "            loop over disability_cols=['AF6','AF8','AF9','AF10','AF11','AF12'] and yield the result in a generator\n",
    "            concat all over axis=0\n",
    "            '''\n",
    "            print('generating Table 12')\n",
    "            df=self.data_wm.copy()\n",
    "            df_filtered=df[df['HL6']>=5].copy()\n",
    "\n",
    "            df_total=[]\n",
    "            for dis in self.disability_cols:\n",
    "                #map the lables to the values\n",
    "                df_filtered[dis]=df_filtered[dis].map(self.disability_levels)\n",
    "\n",
    "                df_ages=[]\n",
    "                for age in ['agegrp5p','agegrp15p','agegrp25p']:\n",
    "\n",
    "                    r=pd.crosstab([df_filtered['HH6'],df_filtered[dis]],\n",
    "                    [df_filtered['edu_level'],df_filtered[age]],\n",
    "                    rownames=['Area','Disability level'],colnames=['Edu attainment','Age'], values=df_filtered['wmweight'],\n",
    "                    aggfunc='sum',dropna=True)\n",
    "                    #add the disability type as a column\n",
    "                    r['disability type']=self.dis_names[dis]\n",
    "                    df_ages.append(r)\n",
    "\n",
    "                #concatenate on axis=0   \n",
    "                t=pd.concat(df_ages, axis=0)\n",
    "                df_total.append(t)\n",
    "\n",
    "            T=pd.concat(df_total, axis=0)\n",
    "            #bring the disability type column to the front\n",
    "            newcols_list=list(T.columns)\n",
    "            newcols=[newcols_list[-1]]+newcols_list[:-1]\n",
    "            T=T[newcols]\n",
    "            T.to_excel('Table 12 EducationAttainment_type.xlsx')\n",
    "\n",
    "            ################################################################\n",
    "            '''Table 13: School attendance of population (5 years and older), by sex, age, location and disability status\n",
    "            filter on age HL6>=5\n",
    "            rows:['Area' (HH6),school attendance (WB5),'Disability','disability_combined']\n",
    "            columns:agegrp4_1[5-9,10-14,15-19,20-24,25-29,30+]\n",
    "            '''\n",
    "            print('generating Table 13')\n",
    "            df=self.data_wm.copy()\n",
    "            df_filtered=df[df['HL6']>=5].copy()\n",
    "\n",
    "            r=pd.crosstab([df_filtered['HH6'],df_filtered['WB5'],df_filtered['disability_combined']],\n",
    "            [df_filtered['agegrp4_1']],\n",
    "            rownames=['Area','school attendance','disability_combined'],\n",
    "            colnames=['Age'], values=df_filtered['wmweight'],\n",
    "            aggfunc='sum',dropna=False)\n",
    "\n",
    "            r.to_excel('Table 13 school attendance.xlsx')\n",
    "\n",
    "            ##############################################################\n",
    "            '''Table 14 School attendance of persons with disabilities (5 years and older), by type of disability, sex, age and location \n",
    "            filter on age HL6>=5\n",
    "            rows:['Area' (HH6),school attendance (WB5),'Disability','disability_combined']\n",
    "            columns: disability types, by agegrp4_2 [5-9,10-14,15-19,20-24,25-64]\n",
    "            loop over disability types ['AF6','AF8','AF9','AF10','AF11','AF12'] to produce xtab with that specific disability type\n",
    "            then concatenate into a single dataframe\n",
    "            '''\n",
    "\n",
    "            print('generating Table 14')\n",
    "            df=self.data_wm.copy()\n",
    "            df_filtered=df[df['HL6']>=5].copy()\n",
    "\n",
    "            df_total=[]\n",
    "            for dis in self.disability_cols:\n",
    "\n",
    "                r=pd.crosstab([df_filtered['HH6'],df_filtered['WB5'],df_filtered['disability_combined']],\n",
    "                [df_filtered['agegrp4_2']],\n",
    "                rownames=['Area','school attendance','Disability level'],colnames=['age'], values=df_filtered['wmweight'],\n",
    "                aggfunc='sum',dropna=False)\n",
    "                #add the disability type as a column\n",
    "                r['disability type']=self.dis_names[dis]\n",
    "                df_total.append(r)\n",
    "\n",
    "            #concatenate on axis=0   \n",
    "            T=pd.concat(df_total, axis=0)\n",
    "            #append 'disability type' to the row index\n",
    "            T.set_index('disability type', append=True, inplace=True)\n",
    "            #make 'disbaility type' a column on top of age\n",
    "            T=T.unstack(3)\n",
    "            #swapping the order of column levels between age and disability type\n",
    "            T.columns=T.columns.swaplevel(0,1)\n",
    "            #sorting the disability type index\n",
    "            T=T.sort_index(axis=1, level=0)\n",
    "            T.to_excel('Table 14 SchoolAttendance_type.xlsx')\n",
    "\n",
    "            ######################################################################\n",
    "            '''Table 15: \n",
    "            Reasons for not going to/ drop out school for population (5 years and older), by sex, location and disability status\n",
    "            filter on age HL6>=5 \n",
    "            rows: ['Area' (HH6),'Disability','disability_combined']\n",
    "            columns: Reasons for not going to school ???????????????????????????\n",
    "            '''\n",
    "            print('WARNING !!! Table 15 Reasons for not going to school not found')\n",
    "\n",
    "            ######################################################################\n",
    "            \n",
    "            '''Table 16: Literacy status for population (15 years and older), by sex, age, location and disability status\n",
    "            filter on age HL6>=15\n",
    "            rows: ['Area' (HH6),'Disability','disability_combined']\n",
    "            columns: WB14 (can read a part of a sentence), agegrp10 [15-24, 25-64, 65+] and another with 15+ to be concatenated\n",
    "            '''\n",
    "            print('generating Table 16')\n",
    "            df=self.data_wm.copy()\n",
    "            df_filtered=df[df['HL6']>=15].copy()\n",
    "\n",
    "            df_total=[]\n",
    "            for age in ['agegrp10','agegrp15p']:\n",
    "                r=pd.crosstab([df_filtered['HH6'],df_filtered['disability_combined']],\n",
    "                [df_filtered['Literacy'],df_filtered[age]],\n",
    "                rownames=['Area','Disability level'],colnames=['Can read a part of a sentence','age'], \n",
    "                values=df_filtered['wmweight'],aggfunc='sum',dropna=False)\n",
    "                df_total.append(r)\n",
    "            #concatenate the dataframes\n",
    "            T=pd.concat(df_total, axis=1)\n",
    "            T.to_excel('Table 16 Literacy.xlsx')\n",
    "\n",
    "            ########################################################################\n",
    "\n",
    "            '''Table 17: Literacy status for persons with disabilities (15 years and older), by type of disability, sex, age and location\n",
    "            filter on age HL6>=15\n",
    "            rows: ['Area' (HH6),'Disability type','disability_combined'] loop over disability types and concatenate on axis=0\n",
    "            columns: WB14 (can read a part of a sentence), agegrp10 [15-24, 25-64, 65+] and another with 15+ to be concatenated \n",
    "            '''\n",
    "            print('generating Table 17')\n",
    "            df=self.data_wm.copy()\n",
    "            df_filtered=df[df['HL6']>=15].copy()\n",
    "            df_total=[]\n",
    "\n",
    "            for dis in self.disability_cols:\n",
    "                #map the lables to the values\n",
    "                df_filtered[dis]=df_filtered[dis].map(self.disability_levels)\n",
    "\n",
    "                df_ages=[]\n",
    "                for age in ['agegrp10','agegrp15p']:\n",
    "\n",
    "                    r=pd.crosstab([df_filtered['HH6'],df_filtered['disability_combined']],\n",
    "                    [df_filtered['WB14'],df_filtered[age]],\n",
    "                    rownames=['Area','Disability level'],colnames=['Can read a part of a sentence','Age'],\n",
    "                    values=df_filtered['wmweight'],aggfunc='sum',dropna=True)\n",
    "                    #add the disability type as a column\n",
    "                    r['disability type']=self.dis_names[dis]\n",
    "                    df_ages.append(r)\n",
    "\n",
    "                #concatenate on axis=0   \n",
    "                t=pd.concat(df_ages, axis=0)\n",
    "                df_total.append(t)\n",
    "\n",
    "            T=pd.concat(df_total, axis=0)\n",
    "            #bring the disability type column to the front\n",
    "            newcols_list=list(T.columns)\n",
    "            newcols=[newcols_list[-1]]+newcols_list[:-1]\n",
    "            T=T[newcols]\n",
    "            T.to_excel('Table 17 Literacy_type_age.xlsx')\n",
    "\n",
    "            #######################################################################\n",
    "\n",
    "            '''Table 18: Household education expenditures, by location and disability status\n",
    "            rows: ['Area' (HH6),'Disability','disability_combined']\n",
    "            columns: household education expenditure ????????\n",
    "            '''\n",
    "            print('generating Table 18')\n",
    "            df=self.data_wm.copy()\n",
    "            print('WARNING !!! Table 18 household education expenditure not found')\n",
    "\n",
    "            #######################################################################\n",
    "\n",
    "            '''Table 19: Activity status of population (15 years and older), by sex, age, location and disability status\n",
    "            filter on age HL6>=15\n",
    "            rows: ['Area' (HH6),'Current activity status' ????????????? ,'Disability','disability_combined']\n",
    "            columns: agegrp5\n",
    "            '''\n",
    "\n",
    "            ########################################################################\n",
    "            \n",
    "            '''Table 32: (VERIFIED) Population with mobile phones and use internet, by sex, age, location and disability status\n",
    "            rows: ['Area' (HH6),'Disability','disability_combined']\n",
    "            columns: Own mobile phone ['MT11', age_ict] & ['MT10': 'Internet usage in the last 3 months' , age_ict]\n",
    "            ['MT12': 'mobile usage in the last 3 months' , age_ict] concatenate both tables\n",
    "            '''\n",
    "\n",
    "            print('generating Table 32')\n",
    "            df=self.data_wm.copy()\n",
    "            df_total=[]\n",
    "\n",
    "            multiindex_cols=[]\n",
    "\n",
    "            for col in ['MT11','MT10','MT12']:\n",
    "                r=pd.crosstab([df['HH6'],df['disability_combined']],\n",
    "                [df[col],df['age_ict']],\n",
    "                rownames=['Area','Disability level'],colnames=[self.col_names_wm[col],'age'], \n",
    "                values=df['wmweight'],aggfunc='sum',dropna=False)\n",
    "                df_total.append(r)\n",
    "                #create the multiindex col and append to multiindex_cols\n",
    "                idx=[]\n",
    "                for i in r.columns:\n",
    "                    l=list(i)\n",
    "                    l.insert(0,self.col_names_wm[col])\n",
    "                    multiindex_cols.append(tuple(l))\n",
    "                \n",
    "            #concatenate the dataframes\n",
    "            T=pd.concat(df_total, axis=1)\n",
    "            cols=pd.MultiIndex.from_tuples(multiindex_cols)\n",
    "            #restructure the columns\n",
    "            T.columns=cols\n",
    "                \n",
    "            #concatenate the dataframes\n",
    "            T=pd.concat(df_total, axis=1)\n",
    "            T.to_excel('Table 32 ICT.xlsx')\n",
    "            #############################################################################\n",
    "\n",
    "            '''Table 33:Persons with disabilities with mobile phones, by type of disability, sex, age and location\n",
    "            filter on 'MT12': 'usage of mobile during last 3 months' {1.0: 'rarely yes', 2:'at least once a week','3':almost everyday'}\n",
    "            rows: ['Area' (HH6),'Disability','disability_combined']\n",
    "            columns: loop over disability_cols=['AF6','AF8','AF9','AF10','AF11','AF12']\n",
    "            '''\n",
    "\n",
    "            print('generating Table 33')\n",
    "            df=self.data_wm.copy()\n",
    "            df_filtered=df[(df['MT12']==1) | (df['MT12']==2) | (df['MT12']==3)].copy()\n",
    "            df_filtered['MT12']=df_filtered['MT12'].map(self.col_vals_wm['MT12'])\n",
    "            df_total=[]\n",
    "\n",
    "            for col in self.disability_cols:\n",
    "                #map the lables to the values\n",
    "                df_filtered[col]=df_filtered[col].map(self.disability_levels)\n",
    "\n",
    "                r=pd.crosstab([df_filtered['HH6']],\n",
    "                [df_filtered[col]],\n",
    "                rownames=['Area'],colnames=['Disability type'], \n",
    "                values=df_filtered['wmweight'],aggfunc='sum',dropna=False).stack()\n",
    "                r.name=self.dis_names[col]\n",
    "                df_total.append(r)\n",
    "\n",
    "            #concatenate the dataframes\n",
    "            T=pd.concat(df_total, axis=1)\n",
    "            T.to_excel('Table 33 mobilephine_type.xlsx')\n",
    "\n",
    "            ###############################################################\n",
    "\n",
    "            '''Table 34:Population receiving social grants/ benefits/ health insurance, by sex, location and disability status\n",
    "            rows: ['Area' (HH6),'Disability','disability_combined']\n",
    "            columns: Disability benefits??????????????, Social assistance cash benefits?????????????\n",
    "            '''\n",
    "\n",
    "            print('generating Table 34')\n",
    "            df=self.data_wm.copy()\n",
    "            print('WARNING !!! Table 34 Disability benefits, Social assistance cash benefits, not found')\n",
    "\n",
    "            ###############################################################\n",
    "            \n",
    "            '''Table 35:(VERIFIED) Population (15 years and older) who currently use any tobacco product on a \n",
    "            daily or non-daily basis, by sex, age, location and disability status\n",
    "            filter on age HL6>=15 & 'TA3': 'Currently smoking cigarettes'{1.0: 'YES', 2.0: 'NO', 9.0: 'NO RESPONSE'}\n",
    "            * Tobacco use.\n",
    "            IF ((TA1 = 9 | TA3 = 9 | TA5 = 99) | (TA6 = 9 | TA7 = 9|TA9=99) | (TA10 = 9 | TA11 = 9 | TA13 = 99)) TobaccoUse = missing.\n",
    "            IF ((TA1 = 2 | TA2 = 0 | TA3 = 2 | TA5 = 0) & (TA6 = 2 | TA7 = 2 | TA9=0) & (TA10 = 2|TA11 = 2 | TA13 = 0)) TobaccoUse = non-smoker.\n",
    "            IF ((TA5 > 0 & TA5 <99) | (TA9 > 0 & TA9 <99) | (TA13 > 0 & TA13 <99)) TobaccoUse = smoker.\n",
    "            rows: ['Area' (HH6),'Disability','disability_combined']\n",
    "            columns: 'TA3': 'Currently smoking cigarettes' with agegrp15p, agegrp10\n",
    "            '''\n",
    "            print('generating Table 35')\n",
    "            df=self.data_wm.copy()\n",
    "            df=self.data_wm.copy()\n",
    "            df_filtered=df[df['HL6']>=15].copy()\n",
    "            df_total=[]\n",
    "\n",
    "            for age in ['agegrp15p','agegrp10']:\n",
    "                #for the xtab with smoking status\n",
    "                r1=pd.crosstab([df_filtered['HH6'],df_filtered['disability_combined']],\n",
    "                [df_filtered['Smoker'],df_filtered[age]],\n",
    "                rownames=['Area','Disability level'],colnames=['Use of any tobacco product','Disability type'], \n",
    "                values=df_filtered['wmweight'],aggfunc='sum',dropna=False)\n",
    "                df_total.append(r1)\n",
    "\n",
    "            # concatenate the dataframes\n",
    "            T=pd.concat(df_total, axis=1)\n",
    "            T.sort_index(axis=1, level=1)\n",
    "            T.to_excel('Table 35 Tobacco_use.xlsx')\n",
    "\n",
    "            #############################################################\n",
    "            \n",
    "            '''Table 36:Women of reproductive age (15-49 years) who have their need for family \n",
    "            planning satisfied with modern methods, by location and disability status\n",
    "            filter on age HL6>=15 & HL6<=49\n",
    "            rows: ['Area' (HH6),'Disability','disability_combined']\n",
    "            columns: 'CP2': 'Currently using a method to avoid pregnancy'\n",
    "\n",
    "            modern methods\n",
    "            'CP4A': {'?': 'NO RESPONSE', 'A': 'FEMALE STERILIZATION'},\n",
    "            'CP4B': {'?': 'NO RESPONSE', 'B': 'MALE STERILIZATION'},\n",
    "            'CP4C': {'?': 'NO RESPONSE', 'C': 'IUD'},\n",
    "            'CP4D': {'?': 'NO RESPONSE', 'D': 'INJECTABLES'},\n",
    "            'CP4E': {'?': 'NO RESPONSE', 'E': 'IMPLANTS'},\n",
    "            'CP4F': {'?': 'NO RESPONSE', 'F': 'PILL'},\n",
    "            'CP4G': {'?': 'NO RESPONSE', 'G': 'MALE CONDOM'},\n",
    "            'CP4H': {'?': 'NO RESPONSE', 'H': 'FEMALE CONDOM'},\n",
    "            'CP4I': {'?': 'NO RESPONSE', 'I': 'DIAPHRAGM'},\n",
    "            'CP4J': {'?': 'NO RESPONSE', 'J': 'FOAM / JELLY'}\n",
    "            \n",
    "            traditional methods:\n",
    "            'CP4K': {'?': 'NO RESPONSE', 'K': 'LACTATIONAL AMENORRHOEA METHOD (LAM)'},\n",
    "            'CP4L': {'?': 'NO RESPONSE', 'L': 'PERIODIC ABSTINENCE / RHYTHM'},\n",
    "            'CP4M': {'?': 'NO RESPONSE', 'M': 'WITHDRAWAL'},\n",
    "            'CP4X': {'?': 'NO RESPONSE', 'X': 'OTHER'}\n",
    "            '''\n",
    "\n",
    "            print('generating Table 36')\n",
    "            df=self.data_wm.copy()\n",
    "            cond=(df['HL6']>=15) & (df['HL6']<=49)\n",
    "            df_filtered=df[cond].copy()\n",
    "\n",
    "            df_total=[]\n",
    "            r1=pd.crosstab([df_filtered['HH6'],df_filtered['disability_combined']],\n",
    "            [df_filtered['CP2']],\n",
    "            rownames=['Area','Disability level'],colnames=[self.col_names_wm['CP2']], \n",
    "            values=df_filtered['wmweight'],aggfunc='sum',dropna=False)\n",
    "            #create a multiindex column\n",
    "            c1=[self.col_names_wm['CP2']]\n",
    "            c2=list(r1.columns)\n",
    "            idx=pd.MultiIndex.from_product([c1,c2])\n",
    "            r1.columns=idx\n",
    "            df_total.append(r1)\n",
    "\n",
    "            #filter the currently married and not pregnant or dont know\n",
    "            cond=((df['MA1']==1) & ((df['CP1']==2) | (df['CP1']==8)))\n",
    "            df_filtered=df[cond].copy()\n",
    "\n",
    "            r2=pd.crosstab([df_filtered['HH6'],df_filtered['disability_combined']],\n",
    "            [df_filtered['modern_contraceptive']],\n",
    "            rownames=['Area','Disability level'],colnames=['Modern contraceptive method'], \n",
    "            values=df_filtered['wmweight'],aggfunc='sum',dropna=False)\n",
    "            c1=['modern_contraceptive']\n",
    "            c2=list(r2.columns)\n",
    "            idx=pd.MultiIndex.from_product([c1,c2])\n",
    "            r2.columns=idx\n",
    "            df_total.append(r2)\n",
    "\n",
    "            T=pd.concat(df_total, axis=1)\n",
    "            T.to_excel('Table 36 family plan.xlsx')\n",
    "\n",
    "            ###############################################################\n",
    "\n",
    "            '''Table 37:Births attended by skilled health personnel, by sex, location and disability status\n",
    "            rows: ['Area' (HH6),'Disability','disability_combined']\n",
    "            columns: 'CM17': 'Live births in last two years'\n",
    "            'MN19A': 'Assistance at delivery: Doctor',\n",
    "            'MN19B': 'Assistance at delivery: Nurse / Midwife',\n",
    "            'MN19H': 'Assistance at delivery: Relative / Friend',\n",
    "            'MN19X': 'Assistance at delivery: Other',\n",
    "            'MN19Y': 'Assistance at delivery: No one',\n",
    "            'MN19NR': 'Assistance at delivery: No response'\n",
    "            '''\n",
    "\n",
    "            print('generating Table 37')\n",
    "            df=self.data_wm.copy()\n",
    "            \n",
    "            r=pd.crosstab([df['HH6'],df['disability_combined']],\n",
    "            [df['Birth_Skilled_Per']],\n",
    "            rownames=['Area','Disability level'],colnames=['Brith attended by skilled pers'],\n",
    "            values=df['wmweight'],aggfunc='sum',dropna=False)\n",
    "\n",
    "            r.to_excel('Table 37 skilled health personnel.xlsx')\n",
    "\n",
    "            ################################################################\n",
    "\n",
    "            '''Table 38: Women (15-49 years) who make their own informed decisions regarding sexual relations,\n",
    "            contraceptive use and reproductive health care, by location and disability status\n",
    "            \n",
    "            xtab 1\n",
    "            filter on age HL6>=15 & HL6<=49\n",
    "            rows: ['Area' (HH6),'Disability','disability_combined']\n",
    "            columns: 'MA1': 'Currently married or living with a man'\n",
    "\n",
    "            xtab 2\n",
    "            filter on age (HL6>=15 & HL6<=49) and 'MA1': {1.0: 'YES, CURRENTLY MARRIED'}\n",
    "            rows: ['Area' (HH6),'Disability','disability_combined']\n",
    "            columns: could not find the below\n",
    "            \"for whom decision on health care for themselves is not usually made by the husband/partner or someone else\n",
    "            \" for whom the decision on contraception is not mainly made by the husband/partner\n",
    "            \"who can say no to sex\n",
    "            '''\n",
    "\n",
    "            print('generating Table 38')\n",
    "            df=self.data_wm.copy()\n",
    "            cond=(df['HL6']>=15) & (df['HL6']<=49)\n",
    "            df_filtered=df[cond].copy()\n",
    "            print('WARNING !!! Table 38 related columns, not found')\n",
    "\n",
    "            ##################################################################\n",
    "\n",
    "            '''Table 39: Population with large household expenditures on health, by sex, location and disability status\n",
    "            rows: ['Area' (HH6),'Disability','disability_combined']\n",
    "            '''\n",
    "\n",
    "            print('generating Table 39')\n",
    "            df=self.data_wm.copy()\n",
    "            cond=(df['HL6']>=15) & (df['HL6']<=49)\n",
    "            df_filtered=df[cond].copy()\n",
    "            print('WARNING !!! Table 39 household expenditure or income, not found')\n",
    "\n",
    "\n",
    "        except Exception as e:\n",
    "            raise(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating Table 1\n",
      "Table 1 generated and saved\n",
      "generating Table 2\n",
      "processing column AF6\n",
      "processing column AF8\n",
      "processing column AF9\n",
      "processing column AF10\n",
      "processing column AF11\n",
      "processing column AF12\n",
      "Table 2 generated and saved\n",
      "WARNING !!! Table 3 cause of disability not found\n",
      "generating Table 4\n",
      "Table 4 generated and saved\n",
      "generating Table 5\n",
      "Table 5 generated and saved\n",
      "generating Table 6.1\n",
      "Table 6.1 generated and saved\n",
      "generating Table 6.2\n",
      "Table 6.2 generated and saved\n",
      "generating Table 7\n",
      "selfing column AF6\n",
      "selfing column AF8\n",
      "selfing column AF9\n",
      "selfing column AF10\n",
      "selfing column AF11\n",
      "selfing column AF12\n",
      "Table 7 generated and saved\n",
      "generating Table 8\n",
      "Table 8.1 generated and saved\n",
      "Table 8.2 generated and saved\n",
      "processing column AF6\n",
      "processing column AF8\n",
      "processing column AF9\n",
      "processing column AF10\n",
      "processing column AF11\n",
      "processing column AF12\n",
      "Table 9 generated and saved\n",
      "generating Table 10\n",
      "Table 10 generated and saved\n",
      "generating Table 11\n",
      "Table 11 generated and saved\n",
      "generating Table 12\n",
      "generating Table 13\n",
      "generating Table 14\n",
      "WARNING !!! Table 15 Reasons for not going to school not found\n",
      "generating Table 16\n",
      "generating Table 17\n",
      "generating Table 18\n",
      "WARNING !!! Table 18 household education expenditure not found\n",
      "generating Table 32\n",
      "generating Table 33\n",
      "generating Table 34\n",
      "WARNING !!! Table 34 Disability benefits, Social assistance cash benefits, not found\n",
      "generating Table 35\n",
      "generating Table 36\n",
      "generating Table 37\n",
      "generating Table 38\n",
      "WARNING !!! Table 38 related columns, not found\n",
      "generating Table 39\n",
      "WARNING !!! Table 39 household expenditure or income, not found\n"
     ]
    }
   ],
   "source": [
    "xtab=crosstab()\n",
    "xtab.generate_xtabs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0b35042a3e9702dfa19af850771da1f579b71240f0eb9d6f872f3083a53479fb"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 ('mics': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
